{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22160802-0004-4506-a81c-8d4a945e7196",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_force_compilation_parallelism=1\"\n",
    "# os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_strict_conv_algorithm_picker=false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87a2cb-8351-4e3e-b60e-3a6c6f73d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import hamux as hmx\n",
    "import treex as tx\n",
    "from flax import linen as nn # For initializers\n",
    "import optax\n",
    "import jax.tree_util as jtu\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7c026-22db-4526-b1bf-dbbfaa14e37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GpuDevice(id=0, process_index=0)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ba2fa-f4d5-40b4-b706-90d33ec4d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(tx.Module):\n",
    "    model: tx.Module\n",
    "    optimizer: tx.Optimizer\n",
    "    apply_fn: Callable\n",
    "    filter_betas: bool\n",
    "    rng: jnp.ndarray = tx.Rng.node()\n",
    "    eval_rng: jnp.ndarray = tx.Rng.node()\n",
    "\n",
    "    def __init__(\n",
    "        self, model, optimizer, apply_fn, rng, filter_betas=False, do_normal_init=False\n",
    "    ):\n",
    "        self.filter_betas = filter_betas\n",
    "        self.model = model\n",
    "        self.optimizer = tx.Optimizer(optimizer).init(self.params)\n",
    "        self.apply_fn = apply_fn\n",
    "        self.rng, self.eval_rng = jax.random.split(rng)\n",
    "        self.do_normal_init = do_normal_init\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        if self.filter_betas:\n",
    "            return self.model.filter(lambda x: \"beta\" not in x.name)\n",
    "        return self.model.filter(tx.Parameter)\n",
    "\n",
    "    def apply_updates(self, grads):\n",
    "        new_params = self.optimizer.update(grads, self.params)\n",
    "        self.model = self.model.merge(new_params)\n",
    "        return self\n",
    "\n",
    "\n",
    "def cross_entropy_loss(*, probs, labels):\n",
    "    n_classes = probs.shape[-1]\n",
    "    labels_onehot = jax.nn.one_hot(labels, num_classes=n_classes)\n",
    "    smoothed_labels = (0.1 / n_classes + labels_onehot)\n",
    "    smoothed_labels = smoothed_labels / jnp.abs(smoothed_labels).sum(-1, keepdims=True)\n",
    "\n",
    "    stable_probs = (probs + 1e-6) / (1+(1e-6)*n_classes)\n",
    "    loss = -jnp.sum(smoothed_labels * jnp.log(stable_probs), axis=-1).mean()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def compute_metrics(*, probs, labels):\n",
    "    loss = cross_entropy_loss(probs=probs, labels=labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(probs, -1) == labels)\n",
    "    metrics = {\n",
    "      \"probs_min\": probs.min(),\n",
    "      'probs_max': probs.max(),\n",
    "      'loss': loss,\n",
    "      'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    if state.do_normal_init:\n",
    "        rng, state.rng = jax.random.split(state.rng)\n",
    "    else:\n",
    "        rng = None\n",
    "\n",
    "    def loss_fn(params):\n",
    "        state.model = state.model.merge(params)\n",
    "        x = batch[\"image\"]\n",
    "        probs = state.apply_fn(state.model, x, rng=rng)\n",
    "        loss = cross_entropy_loss(probs=probs, labels=batch[\"label\"])\n",
    "        return loss, (probs, state)\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, (probs, state)), grads = grad_fn(state.params)\n",
    "\n",
    "    state = state.apply_updates(grads)\n",
    "    metrics = compute_metrics(probs=probs, labels=batch[\"label\"])\n",
    "    return state, metrics\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(state, batch):\n",
    "    x = batch[\"image\"]\n",
    "    if state.do_normal_init:\n",
    "        rng = state.eval_rng\n",
    "    else:\n",
    "        rng = None\n",
    "    probs = state.apply_fn(state.model, x, rng=rng)\n",
    "    return compute_metrics(probs=probs, labels=batch['label'])\n",
    "\n",
    "def train_epoch(state, train_dl, epoch):\n",
    "    \"\"\"Train for a single epoch.\"\"\"\n",
    "    batch_metrics = []\n",
    "    bs = train_dl.batch_size\n",
    "    for i, batch in enumerate(tqdm(train_dl, leave=False)):\n",
    "        batch = {\"image\": jnp.array(batch[0]), \"label\": jnp.array(batch[1])}\n",
    "        state, metrics = train_step(state, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "\n",
    "    # compute mean of metrics across each batch in epoch.\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    epoch_metrics_np = {\n",
    "        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "        for k in batch_metrics_np[0]\n",
    "    }\n",
    "    return state, epoch_metrics_np[\"loss\"], epoch_metrics_np[\"accuracy\"]\n",
    "\n",
    "\n",
    "def eval_model(state, test_dl):\n",
    "    batch_metrics = []\n",
    "\n",
    "    for i, batch in enumerate(test_dl):\n",
    "        batch = {\"image\": jnp.array(batch[0]), \"label\": jnp.array(batch[1])}\n",
    "\n",
    "        metrics = eval_step(state, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    summary = {\n",
    "        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "        for k in batch_metrics_np[0]\n",
    "    }\n",
    "\n",
    "    return summary[\"loss\"], summary[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbbc562-2435-4fc1-bb5a-1fd497bf2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from hamux.datasets import *\n",
    "\n",
    "dl_args = DataloadingArgs(\n",
    "    dataset=\"torch/CIFAR10\",\n",
    "    # aa=\"rand\",\n",
    "    aa=None,\n",
    "    reprob=0.2,\n",
    "    vflip=0.0,\n",
    "    hflip=0.5,\n",
    "    scale=(0.2, 1.0),\n",
    "    batch_size=args.batch_size,\n",
    "    color_jitter=0.5,\n",
    "    validation_batch_size=2 * args.batch_size,\n",
    ")\n",
    "data_config = DataConfigCIFAR10(input_size=(3, 32, 32))\n",
    "\n",
    "train_dl, eval_dl = create_dataloaders(dl_args, data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13298baa-eaff-4b3f-afef-158e9d270d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hamux]",
   "language": "python",
   "name": "conda-env-hamux-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
