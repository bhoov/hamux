{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b441e5-c359-412d-98ba-7613144e496e",
   "metadata": {},
   "source": [
    "# Minimal CIFAR Demo for Classification\n",
    "\n",
    "A minimal demo on the CIFAR training dataset for classification. A lot of this notebook includes boilerplate. Look for the 🚀 symbol for important notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f22e7f2-703d-458d-a9b7-3fa209a29702",
   "metadata": {},
   "source": [
    "Load important libraries. Modify GPU usage details here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22160802-0004-4506-a81c-8d4a945e7196",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_force_compilation_parallelism=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87a2cb-8351-4e3e-b60e-3a6c6f73d9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/bhoover30/miniconda3/envs/hamux/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import hamux as hmx\n",
    "import treex as tx\n",
    "from flax import linen as nn # For initializers\n",
    "import optax\n",
    "import jax.tree_util as jtu\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from loguru import logger\n",
    "from einops import rearrange\n",
    "from tqdm.auto import trange, tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7c026-22db-4526-b1bf-dbbfaa14e37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GpuDevice(id=0, process_index=0)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e2aa82-2cee-4607-9d56-eea2ce808491",
   "metadata": {},
   "source": [
    "# Training functions\n",
    "\n",
    "For the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ba2fa-f4d5-40b4-b706-90d33ec4d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(tx.Module):\n",
    "    model: tx.Module\n",
    "    optimizer: tx.Optimizer\n",
    "    apply_fn: Callable\n",
    "    filter_betas: bool\n",
    "    rng: jnp.ndarray = tx.Rng.node()\n",
    "    eval_rng: jnp.ndarray = tx.Rng.node()\n",
    "\n",
    "    def __init__(\n",
    "        self, model, optimizer, apply_fn, rng, filter_betas=False, do_normal_init=False\n",
    "    ):\n",
    "        self.filter_betas = filter_betas\n",
    "        self.model = model\n",
    "        self.optimizer = tx.Optimizer(optimizer).init(self.params)\n",
    "        self.apply_fn = apply_fn\n",
    "        self.rng, self.eval_rng = jax.random.split(rng)\n",
    "        self.do_normal_init = do_normal_init\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        if self.filter_betas:\n",
    "            return self.model.filter(lambda x: \"beta\" not in x.name)\n",
    "        return self.model.filter(tx.Parameter)\n",
    "\n",
    "    def apply_updates(self, grads):\n",
    "        new_params = self.optimizer.update(grads, self.params)\n",
    "        self.model = self.model.merge(new_params)\n",
    "        return self\n",
    "\n",
    "\n",
    "def cross_entropy_loss(*, probs, labels):\n",
    "    n_classes = probs.shape[-1]\n",
    "    labels_onehot = jax.nn.one_hot(labels, num_classes=n_classes)\n",
    "    smoothed_labels = (0.1 / n_classes + labels_onehot)\n",
    "    smoothed_labels = smoothed_labels / jnp.abs(smoothed_labels).sum(-1, keepdims=True)\n",
    "\n",
    "    stable_probs = (probs + 1e-6) / (1+(1e-6)*n_classes)\n",
    "    loss = -jnp.sum(smoothed_labels * jnp.log(stable_probs), axis=-1).mean()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def compute_metrics(*, probs, labels):\n",
    "    loss = cross_entropy_loss(probs=probs, labels=labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(probs, -1) == labels)\n",
    "    metrics = {\n",
    "      \"probs_min\": probs.min(),\n",
    "      'probs_max': probs.max(),\n",
    "      'loss': loss,\n",
    "      'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    if state.do_normal_init:\n",
    "        rng, state.rng = jax.random.split(state.rng)\n",
    "    else:\n",
    "        rng = None\n",
    "\n",
    "    def loss_fn(params):\n",
    "        state.model = state.model.merge(params)\n",
    "        x = batch[\"image\"]\n",
    "        probs = state.apply_fn(state.model, x, rng=rng)\n",
    "        loss = cross_entropy_loss(probs=probs, labels=batch[\"label\"])\n",
    "        return loss, (probs, state)\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, (probs, state)), grads = grad_fn(state.params)\n",
    "\n",
    "    state = state.apply_updates(grads)\n",
    "    metrics = compute_metrics(probs=probs, labels=batch[\"label\"])\n",
    "    return state, metrics\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(state, batch):\n",
    "    x = batch[\"image\"]\n",
    "    if state.do_normal_init:\n",
    "        rng = state.eval_rng\n",
    "    else:\n",
    "        rng = None\n",
    "    probs = state.apply_fn(state.model, x, rng=rng)\n",
    "    return compute_metrics(probs=probs, labels=batch['label'])\n",
    "\n",
    "def train_epoch(state, train_dl, epoch):\n",
    "    \"\"\"Train for a single epoch.\"\"\"\n",
    "    batch_metrics = []\n",
    "    bs = train_dl.batch_size\n",
    "    for i, batch in enumerate(tqdm(train_dl, leave=False)):\n",
    "        batch = {\"image\": jnp.array(batch[0]), \"label\": jnp.array(batch[1])}\n",
    "        state, metrics = train_step(state, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "\n",
    "    # compute mean of metrics across each batch in epoch.\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    epoch_metrics_np = {\n",
    "        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "        for k in batch_metrics_np[0]\n",
    "    }\n",
    "    return state, epoch_metrics_np[\"loss\"], epoch_metrics_np[\"accuracy\"]\n",
    "\n",
    "\n",
    "def eval_model(state, test_dl):\n",
    "    batch_metrics = []\n",
    "\n",
    "    for i, batch in enumerate(test_dl):\n",
    "        batch = {\"image\": jnp.array(batch[0]), \"label\": jnp.array(batch[1])}\n",
    "\n",
    "        metrics = eval_step(state, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    summary = {\n",
    "        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "        for k in batch_metrics_np[0]\n",
    "    }\n",
    "\n",
    "    return summary[\"loss\"], summary[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f582c18-5dc3-4e1d-817f-51dad2f7a98b",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "We load the CIFAR dataset with selected augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbbc562-2435-4fc1-bb5a-1fd497bf2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from hamux.datasets import *\n",
    "\n",
    "dl_args = DataloadingArgs(\n",
    "    dataset=\"torch/CIFAR10\",\n",
    "    # aa=\"rand\",\n",
    "    aa=None,\n",
    "    reprob=0.,\n",
    "    vflip=0.0,\n",
    "    hflip=0.5,\n",
    "    scale=(0.2, 1.0),\n",
    "    batch_size=100,\n",
    "    color_jitter=0.5,\n",
    "    validation_batch_size=1000,\n",
    ")\n",
    "data_config = DataConfigCIFAR10(input_size=(3, 32, 32))\n",
    "\n",
    "train_dl, eval_dl = create_dataloaders(dl_args, data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f561396-39a6-4e41-a6f7-c4d56c77818b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in train_dl:\n",
    "    imgs, labels = batch\n",
    "    break\n",
    "    \n",
    "plt.imshow(data_config.show(imgs[8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d52c96-7861-4ed3-9d20-691c23b79311",
   "metadata": {},
   "source": [
    "# Model Creation from Scratch\n",
    "\n",
    "We rewrite the synapse and layer for a simple 2 layer CIFAR network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054a2550-d0cd-4346-b386-e340a8e5032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HopfieldNetworkAsSynapse(hmx.Synapse):\n",
    "    \"\"\"A simple reimplementation of a Hopfield Network as a synapse, returning the alignment\"\"\"\n",
    "    W1: jnp.ndarray = tx.Parameter.node() # treex's preferred way of declaring an attribute as a parameter\n",
    "    W2: jnp.ndarray = tx.Parameter.node()\n",
    "    nhid: int\n",
    "    beta: float = tx.Parameter.node()\n",
    "    \n",
    "    def __init__(self, nhid:int, beta_init=0.1):\n",
    "        self.nhid = nhid\n",
    "        self.beta = beta_init\n",
    "    \n",
    "    def __call__(self, g1, g2):\n",
    "        \"\"\"The alignment function, defined on an unbatched `g`\"\"\"\n",
    "        if self.initializing():\n",
    "            self.W1 = nn.initializers.normal(0.02)(tx.next_key(), g1.shape + (self.nhid,))\n",
    "            self.W2 = nn.initializers.normal(0.02)(tx.next_key(), g2.shape + (self.nhid,))\n",
    "        hidsig = g1 @ self.W1 + g2 @ self.W2\n",
    "        hid_lagrangian_value = 1/self.beta * jnp.exp(self.beta * hidsig)\n",
    "        return hid_lagrangian_value.sum(-1)\n",
    "    \n",
    "ImageLayer = hmx.Layer(hmx.lagrangians.LTanh(beta=0.1), (32*32*3,))\n",
    "LabelLayer = hmx.Layer(hmx.lagrangians.LSoftmax(beta=0.1), (10,))\n",
    "\n",
    "layers = [ImageLayer, LabelLayer]\n",
    "synapses = [HopfieldNetworkAsSynapse(nhid=1000)]\n",
    "connections = [((0,1),0)]\n",
    "ham = hmx.HAM(layers, synapses, connections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6a204-b294-49f5-b326-41743405c754",
   "metadata": {},
   "source": [
    "A layer is uniquely defined by a lagrangian function and a neuron shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806ff11d-0bf7-4fb3-b1cd-d27c5ce89ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd(model, x, depth=4, dt=1, rng=None):\n",
    "    \"\"\"A pure function to extract desired information from the configured HAM, applied on batched inputs\"\"\"\n",
    "    # Initialize hidden states to our image\n",
    "    xs = model.init_states(x.shape[0], rng=rng)\n",
    "    xs[0] = jnp.array(rearrange(x, \"... c h w -> ... (c h w)\"))\n",
    "\n",
    "    # Masks allow us to clamp our visible data over time\n",
    "    masks = jtu.tree_map(lambda x: jnp.ones_like(x, dtype=jnp.int8), xs)\n",
    "    masks[0] = jnp.zeros_like(masks[0], dtype=jnp.int8)  # Don't evolve images\n",
    "\n",
    "    for i in range(depth):\n",
    "        updates = model.vupdates(xs)  # Calculate the updates\n",
    "        xs = model.step(\n",
    "            xs, updates, dt=dt, masks=masks\n",
    "        )  # Add them to our current states\n",
    "\n",
    "    # All labels have a softmax activation function as the last layer, spitting out probabilities\n",
    "    return model.layers[-1].g(xs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef102b-89b8-4b41-8ba2-ed3a805ac5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax_key = jax.random.PRNGKey(0)\n",
    "k1, jax_key = jax.random.split(jax_key)\n",
    "lr = 0.001\n",
    "num_epochs = 100\n",
    "states, ham = ham.init_states_and_params(k1, bs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44f5d31-883c-448f-a338-b71dc2960ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/bhoover30/miniconda3/envs/hamux/lib/python3.9/site-packages/treex/optimizer.py:79: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  params = jax.tree_leaves(params)\n",
      "2022-10-18 15:31:21.411 | INFO     | __main__:<module>:31 - NParams=3082003\n",
      "/nethome/bhoover30/miniconda3/envs/hamux/lib/python3.9/site-packages/treex/module.py:241: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  flat, _ = jax.tree_flatten(self)\n",
      "/nethome/bhoover30/miniconda3/envs/hamux/lib/python3.9/site-packages/treex/utils.py:167: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  tree_types = jax.tree_flatten(\n",
      "/nethome/bhoover30/miniconda3/envs/hamux/lib/python3.9/site-packages/treex/utils.py:375: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  count = sum((x.size if hasattr(x, \"size\") else 0 for x in jax.tree_leaves(obj)), 0)\n",
      "/nethome/bhoover30/miniconda3/envs/hamux/lib/python3.9/site-packages/treex/utils.py:377: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  (x.nbytes if hasattr(x, \"nbytes\") else 0 for x in jax.tree_leaves(obj)), 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path                  </span>┃<span style=\"font-weight: bold\"> module                </span>┃<span style=\"font-weight: bold\"> params                </span>┃<span style=\"font-weight: bold\"> Parameter         </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ *                     │ HAM()                 │                       │                   │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────┤\n",
       "│ .layers[0]            │ Layer()               │ bias: None            │                   │\n",
       "│                       │                       │                       │                   │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────┤\n",
       "│ .layers[0].lagrangian │ LTanh()               │ beta: 0.1             │                   │\n",
       "│                       │                       │                       │                   │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────┤\n",
       "│ .layers[1]            │ Layer()               │ bias: None            │                   │\n",
       "│                       │                       │                       │                   │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────┤\n",
       "│ .layers[1].lagrangian │ LSoftmax()            │ beta: 0.1             │                   │\n",
       "│                       │                       │                       │                   │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────┤\n",
       "│ .synapses[0]          │ HopfieldNetworkAsSyn… │ W1: Parameter(<span style=\"color: #008000; text-decoration-color: #008000\">3072, </span>  │ <span style=\"color: #008000; text-decoration-color: #008000\">3,082,000</span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12.3MB</span> │\n",
       "│                       │                       │ <span style=\"color: #008000; text-decoration-color: #008000\">1000</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>        │                   │\n",
       "│                       │                       │ W2: Parameter(<span style=\"color: #008000; text-decoration-color: #008000\">10, </span>    │                   │\n",
       "│                       │                       │ <span style=\"color: #008000; text-decoration-color: #008000\">1000</span>)    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>      │                   │\n",
       "│                       │                       │ beta: 0.1             │                   │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────┤\n",
       "│<span style=\"font-weight: bold\">                       </span>│<span style=\"font-weight: bold\">                       </span>│<span style=\"font-weight: bold\">                Total: </span>│<span style=\"font-weight: bold\"> </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3,082,000</span><span style=\"font-weight: bold\">  </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">12.3MB</span><span style=\"font-weight: bold\"> </span>│\n",
       "└───────────────────────┴───────────────────────┴───────────────────────┴───────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                                             </span>\n",
       "<span style=\"font-weight: bold\">                             Total Parameters: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3,082,000</span><span style=\"font-weight: bold\">  </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">12.3MB</span><span style=\"font-weight: bold\">                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mParameter        \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ *                     │ HAM()                 │                       │                   │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────┤\n",
       "│ .layers[0]            │ Layer()               │ bias: None            │                   │\n",
       "│                       │                       │                       │                   │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────┤\n",
       "│ .layers[0].lagrangian │ LTanh()               │ beta: 0.1             │                   │\n",
       "│                       │                       │                       │                   │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────┤\n",
       "│ .layers[1]            │ Layer()               │ bias: None            │                   │\n",
       "│                       │                       │                       │                   │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────┤\n",
       "│ .layers[1].lagrangian │ LSoftmax()            │ beta: 0.1             │                   │\n",
       "│                       │                       │                       │                   │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────┤\n",
       "│ .synapses[0]          │ HopfieldNetworkAsSyn… │ W1: Parameter(\u001b[32m3072, \u001b[0m  │ \u001b[32m3,082,000\u001b[0m  \u001b[2m12.3MB\u001b[0m │\n",
       "│                       │                       │ \u001b[32m1000\u001b[0m)  \u001b[2mfloat32\u001b[0m        │                   │\n",
       "│                       │                       │ W2: Parameter(\u001b[32m10, \u001b[0m    │                   │\n",
       "│                       │                       │ \u001b[32m1000\u001b[0m)    \u001b[2mfloat32\u001b[0m      │                   │\n",
       "│                       │                       │ beta: 0.1             │                   │\n",
       "├───────────────────────┼───────────────────────┼───────────────────────┼───────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m                     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m               Total:\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1;32m3,082,000\u001b[0m\u001b[1m  \u001b[0m\u001b[1;2m12.3MB\u001b[0m\u001b[1m \u001b[0m│\n",
       "└───────────────────────┴───────────────────────┴───────────────────────┴───────────────────┘\n",
       "\u001b[1m                                                                                             \u001b[0m\n",
       "\u001b[1m                             Total Parameters: \u001b[0m\u001b[1;32m3,082,000\u001b[0m\u001b[1m  \u001b[0m\u001b[1;2m12.3MB\u001b[0m\u001b[1m                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 15:31:21.424 | INFO     | __main__:<module>:32 - \n"
     ]
    }
   ],
   "source": [
    "# ham, forward_classification = hmx.create_model(args.model)\n",
    "\n",
    "optimizer = optax.adamw(0.001)\n",
    "state = TrainState(\n",
    "    ham,\n",
    "    optimizer,\n",
    "    fwd,\n",
    "    rng=jax_key,\n",
    "    filter_betas=False,\n",
    ")\n",
    "\n",
    "\n",
    "def get_nparams(model):\n",
    "    params, meta = jtu.tree_flatten(model.parameters())\n",
    "\n",
    "    def get_nel(x):\n",
    "        try:\n",
    "            return x.size\n",
    "        except AttributeError:  # float\n",
    "            return 1\n",
    "\n",
    "    return sum([get_nel(p) for p in params])\n",
    "\n",
    "\n",
    "def escape_ansi(line):\n",
    "    import re\n",
    "\n",
    "    ansi_escape = re.compile(r\"(?:\\x1B[@-_]|[\\x80-\\x9F])[0-?]*[ -/]*[@-~]\")\n",
    "    return ansi_escape.sub(\"\", line)\n",
    "\n",
    "logger.info(f\"NParams={get_nparams(state.model)}\")\n",
    "logger.info(escape_ansi(state.model.tabulate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc02748e-1fd3-49b8-b95c-2bbb4847426e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 0/100 [00:00<?, ?epochs/s]\n",
      "  0%|                                                                                 | 0/500 [00:00<?, ?it/s]\u001b[A/nethome/bhoover30/miniconda3/envs/hamux/lib/python3.9/site-packages/treex/optimizer.py:110: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  opt_grads, treedef = jax.tree_flatten(grads)\n",
      "/nethome/bhoover30/miniconda3/envs/hamux/lib/python3.9/site-packages/treex/optimizer.py:111: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  opt_params = jax.tree_leaves(params)\n",
      "/nethome/bhoover30/miniconda3/envs/hamux/lib/python3.9/site-packages/treex/optimizer.py:135: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  return jax.tree_unflatten(treedef, output)\n",
      "\n",
      "  0%|▏                                                                        | 1/500 [00:04<37:03,  4.46s/it]\u001b[A\n",
      "  0%|▎                                                                        | 2/500 [00:07<28:33,  3.44s/it]\u001b[A\n",
      "  1%|▍                                                                        | 3/500 [00:09<25:49,  3.12s/it]\u001b[A\n",
      "  2%|█▎                                                                       | 9/500 [00:10<05:18,  1.54it/s]\u001b[A\n",
      "  3%|██▏                                                                     | 15/500 [00:10<02:32,  3.19it/s]\u001b[A\n",
      "  4%|███▏                                                                    | 22/500 [00:10<01:22,  5.77it/s]\u001b[A\n",
      "  6%|████▏                                                                   | 29/500 [00:10<00:51,  9.13it/s]\u001b[A\n",
      "  7%|█████▎                                                                  | 37/500 [00:10<00:33, 13.95it/s]\u001b[A\n",
      "  9%|██████▍                                                                 | 45/500 [00:10<00:23, 19.59it/s]\u001b[A\n",
      " 11%|███████▋                                                                | 53/500 [00:10<00:17, 26.11it/s]\u001b[A\n",
      " 12%|████████▋                                                               | 60/500 [00:10<00:13, 31.88it/s]\u001b[A\n",
      " 13%|█████████▋                                                              | 67/500 [00:10<00:11, 37.76it/s]\u001b[A\n",
      " 15%|██████████▊                                                             | 75/500 [00:11<00:09, 44.80it/s]\u001b[A\n",
      " 17%|███████████▉                                                            | 83/500 [00:11<00:08, 50.76it/s]\u001b[A\n",
      " 18%|█████████████                                                           | 91/500 [00:11<00:07, 55.86it/s]\u001b[A\n",
      " 20%|██████████████▎                                                         | 99/500 [00:11<00:06, 60.11it/s]\u001b[A\n",
      " 21%|███████████████▏                                                       | 107/500 [00:11<00:06, 62.05it/s]\u001b[A\n",
      " 23%|████████████████▏                                                      | 114/500 [00:11<00:06, 59.08it/s]\u001b[A\n",
      " 24%|█████████████████▏                                                     | 121/500 [00:11<00:06, 59.48it/s]\u001b[A\n",
      " 26%|██████████████████▏                                                    | 128/500 [00:11<00:05, 62.17it/s]\u001b[A\n",
      " 27%|███████████████████▎                                                   | 136/500 [00:11<00:05, 64.55it/s]\u001b[A\n",
      " 29%|████████████████████▎                                                  | 143/500 [00:12<00:05, 65.38it/s]\u001b[A\n",
      " 30%|█████████████████████▍                                                 | 151/500 [00:12<00:05, 67.52it/s]\u001b[A\n",
      " 32%|██████████████████████▍                                                | 158/500 [00:12<00:05, 63.80it/s]\u001b[A\n",
      " 33%|███████████████████████▍                                               | 165/500 [00:12<00:05, 58.96it/s]\u001b[A\n",
      " 34%|████████████████████████▍                                              | 172/500 [00:12<00:05, 59.74it/s]\u001b[A\n",
      " 36%|█████████████████████████▍                                             | 179/500 [00:12<00:05, 61.62it/s]\u001b[A\n",
      " 37%|██████████████████████████▌                                            | 187/500 [00:12<00:04, 64.64it/s]\u001b[A\n",
      " 39%|███████████████████████████▌                                           | 194/500 [00:12<00:04, 65.41it/s]\u001b[A\n",
      " 40%|████████████████████████████▌                                          | 201/500 [00:12<00:04, 65.99it/s]\u001b[A\n",
      " 42%|█████████████████████████████▌                                         | 208/500 [00:13<00:04, 60.02it/s]\u001b[A\n",
      " 43%|██████████████████████████████▌                                        | 215/500 [00:13<00:04, 58.85it/s]\u001b[A\n",
      " 44%|███████████████████████████████▌                                       | 222/500 [00:13<00:04, 61.63it/s]\u001b[A\n",
      " 46%|████████████████████████████████▋                                      | 230/500 [00:13<00:04, 64.72it/s]\u001b[A\n",
      " 47%|█████████████████████████████████▋                                     | 237/500 [00:13<00:03, 65.96it/s]\u001b[A\n",
      " 49%|██████████████████████████████████▊                                    | 245/500 [00:13<00:03, 67.26it/s]\u001b[A\n",
      " 50%|███████████████████████████████████▊                                   | 252/500 [00:13<00:03, 63.18it/s]\u001b[A\n",
      " 52%|████████████████████████████████████▊                                  | 259/500 [00:13<00:04, 57.61it/s]\u001b[A\n",
      " 53%|█████████████████████████████████████▉                                 | 267/500 [00:14<00:03, 61.31it/s]\u001b[A\n",
      " 55%|███████████████████████████████████████                                | 275/500 [00:14<00:03, 64.76it/s]\u001b[A\n",
      " 57%|████████████████████████████████████████▏                              | 283/500 [00:14<00:03, 66.84it/s]\u001b[A\n",
      " 58%|█████████████████████████████████████████▎                             | 291/500 [00:14<00:03, 68.52it/s]\u001b[A\n",
      " 60%|██████████████████████████████████████████▎                            | 298/500 [00:14<00:02, 67.88it/s]\u001b[A\n",
      " 61%|███████████████████████████████████████████▎                           | 305/500 [00:14<00:02, 67.20it/s]\u001b[A\n",
      " 62%|████████████████████████████████████████████▎                          | 312/500 [00:14<00:02, 67.90it/s]\u001b[A\n",
      " 64%|█████████████████████████████████████████████▍                         | 320/500 [00:14<00:02, 69.93it/s]\u001b[A\n",
      " 66%|██████████████████████████████████████████████▌                        | 328/500 [00:14<00:02, 70.54it/s]\u001b[A\n",
      " 67%|███████████████████████████████████████████████▋                       | 336/500 [00:14<00:02, 71.60it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████▊                      | 344/500 [00:15<00:02, 72.91it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████▉                     | 352/500 [00:15<00:02, 70.00it/s]\u001b[A\n",
      " 72%|███████████████████████████████████████████████████                    | 360/500 [00:15<00:02, 65.02it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████▎                  | 368/500 [00:15<00:01, 67.57it/s]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████▍                 | 376/500 [00:15<00:01, 69.39it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████▌                | 384/500 [00:15<00:01, 70.79it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████▋               | 392/500 [00:15<00:01, 71.34it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████▊              | 400/500 [00:15<00:01, 70.25it/s]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████▉             | 408/500 [00:16<00:01, 65.33it/s]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████▉            | 415/500 [00:16<00:01, 65.82it/s]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████           | 423/500 [00:16<00:01, 67.71it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████▏         | 431/500 [00:16<00:00, 69.56it/s]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████▎        | 439/500 [00:16<00:00, 70.94it/s]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████▍       | 447/500 [00:16<00:00, 70.84it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████▌      | 455/500 [00:16<00:00, 64.09it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████▌     | 462/500 [00:16<00:00, 61.26it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████████████████████████████████▋    | 470/500 [00:16<00:00, 64.68it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████████████████████████████████▉   | 478/500 [00:17<00:00, 67.22it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████████████████████████████████  | 486/500 [00:17<00:00, 68.86it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████████████████████████████████ | 493/500 [00:17<00:00, 68.16it/s]\u001b[A\n",
      "                                                                                                              \u001b[A2022-10-18 15:31:42.022 | DEBUG    | __main__:<module>:31 - Couldn't remove _logs/DummyCifar_epoch--1_acc--100.000.pckl, [Errno 2] No such file or directory: '_logs/DummyCifar_epoch--1_acc--100.000.pckl'\n",
      "2022-10-18 15:31:42.044 | INFO     | __main__:<module>:41 - [1/100] | BestAcc: 39.110 | TrainLoss: 2.10 | TrainAcc: 25.72 | curr_val_acc=39.11\n",
      "[1/100] | BestAcc: 39.110 | TrainLoss: 2.10 | TrainAcc: 25.72:   1%| | 1/100 [00:20<33:58, 20.59s/epochs, trai\n",
      "  0%|                                                                                 | 0/500 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▏                                                                        | 1/500 [00:00<01:27,  5.73it/s]\u001b[A\n",
      "  2%|█▎                                                                       | 9/500 [00:00<00:13, 37.44it/s]\u001b[A\n",
      "  3%|██▎                                                                     | 16/500 [00:00<00:10, 47.46it/s]\u001b[A\n",
      "  4%|███▏                                                                    | 22/500 [00:00<00:10, 46.76it/s]\u001b[A\n",
      "  5%|███▉                                                                    | 27/500 [00:00<00:14, 33.28it/s]\u001b[A\n",
      "  7%|█████                                                                   | 35/500 [00:00<00:10, 43.18it/s]\u001b[A\n",
      "  9%|██████▏                                                                 | 43/500 [00:00<00:08, 50.92it/s]\u001b[A\n",
      " 10%|███████▏                                                                | 50/500 [00:01<00:08, 55.45it/s]\u001b[A\n",
      " 11%|████████▏                                                               | 57/500 [00:01<00:07, 58.57it/s]\u001b[A\n",
      " 13%|█████████▏                                                              | 64/500 [00:01<00:07, 61.14it/s]\u001b[A\n",
      " 14%|██████████▎                                                             | 72/500 [00:01<00:06, 64.65it/s]\u001b[A\n",
      " 16%|███████████▌                                                            | 80/500 [00:01<00:06, 66.45it/s]\u001b[A\n",
      " 18%|████████████▋                                                           | 88/500 [00:01<00:06, 68.16it/s]\u001b[A\n",
      " 19%|█████████████▊                                                          | 96/500 [00:01<00:05, 69.81it/s]\u001b[A\n",
      " 21%|██████████████▊                                                        | 104/500 [00:01<00:05, 66.79it/s]\u001b[A\n",
      " 22%|███████████████▊                                                       | 111/500 [00:01<00:06, 63.73it/s]\u001b[A\n",
      " 24%|████████████████▉                                                      | 119/500 [00:02<00:05, 65.82it/s]\u001b[A\n",
      " 25%|██████████████████                                                     | 127/500 [00:02<00:05, 67.29it/s]\u001b[A\n",
      " 27%|███████████████████▏                                                   | 135/500 [00:02<00:05, 68.57it/s]\u001b[A\n",
      " 29%|████████████████████▎                                                  | 143/500 [00:02<00:05, 69.51it/s]\u001b[A\n",
      " 30%|█████████████████████▍                                                 | 151/500 [00:02<00:05, 69.51it/s]\u001b[A\n",
      " 32%|██████████████████████▍                                                | 158/500 [00:02<00:05, 65.27it/s]\u001b[A\n",
      " 33%|███████████████████████▍                                               | 165/500 [00:02<00:05, 64.07it/s]\u001b[A\n",
      " 35%|████████████████████████▌                                              | 173/500 [00:02<00:04, 66.11it/s]\u001b[A\n",
      " 36%|█████████████████████████▌                                             | 180/500 [00:03<00:04, 67.05it/s]\u001b[A\n",
      " 38%|██████████████████████████▋                                            | 188/500 [00:03<00:04, 68.40it/s]\u001b[A\n",
      " 39%|███████████████████████████▊                                           | 196/500 [00:03<00:04, 69.75it/s]\u001b[A\n",
      " 41%|████████████████████████████▊                                          | 203/500 [00:03<00:04, 66.49it/s]\u001b[A\n",
      " 42%|█████████████████████████████▊                                         | 210/500 [00:03<00:04, 62.53it/s]\u001b[A\n",
      " 43%|██████████████████████████████▊                                        | 217/500 [00:03<00:04, 64.33it/s]\u001b[A\n",
      " 45%|███████████████████████████████▉                                       | 225/500 [00:03<00:04, 66.21it/s]\u001b[A\n",
      " 47%|█████████████████████████████████                                      | 233/500 [00:03<00:03, 67.96it/s]\u001b[A\n",
      " 48%|██████████████████████████████████▏                                    | 241/500 [00:03<00:03, 69.24it/s]\u001b[A\n",
      " 50%|███████████████████████████████████▎                                   | 249/500 [00:04<00:03, 70.49it/s]\u001b[A\n",
      " 51%|████████████████████████████████████▍                                  | 257/500 [00:04<00:03, 67.64it/s]\u001b[A\n",
      " 53%|█████████████████████████████████████▍                                 | 264/500 [00:04<00:03, 67.32it/s]\u001b[A\n",
      " 54%|██████████████████████████████████████▌                                | 272/500 [00:04<00:03, 68.60it/s]\u001b[A\n",
      " 56%|███████████████████████████████████████▌                               | 279/500 [00:04<00:03, 68.98it/s]\u001b[A\n",
      " 57%|████████████████████████████████████████▊                              | 287/500 [00:04<00:03, 70.14it/s]\u001b[A\n",
      " 59%|█████████████████████████████████████████▉                             | 295/500 [00:04<00:02, 70.66it/s]\u001b[A\n",
      " 61%|███████████████████████████████████████████                            | 303/500 [00:04<00:02, 70.89it/s]\u001b[A\n",
      " 62%|████████████████████████████████████████████▏                          | 311/500 [00:04<00:02, 70.02it/s]\u001b[A\n",
      " 64%|█████████████████████████████████████████████▎                         | 319/500 [00:05<00:02, 69.52it/s]\u001b[A\n",
      " 65%|██████████████████████████████████████████████▍                        | 327/500 [00:05<00:02, 69.74it/s]\u001b[A\n",
      " 67%|███████████████████████████████████████████████▍                       | 334/500 [00:05<00:02, 68.77it/s]\u001b[A\n",
      " 68%|████████████████████████████████████████████████▌                      | 342/500 [00:05<00:02, 70.28it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████▋                     | 350/500 [00:05<00:02, 68.98it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████▋                    | 357/500 [00:05<00:02, 66.08it/s]\u001b[A\n",
      " 73%|███████████████████████████████████████████████████▋                   | 364/500 [00:05<00:02, 62.42it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████▊                  | 372/500 [00:05<00:01, 66.48it/s]\u001b[A\n",
      " 76%|█████████████████████████████████████████████████████▉                 | 380/500 [00:05<00:01, 67.56it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████                | 388/500 [00:06<00:01, 69.72it/s]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████▏              | 396/500 [00:06<00:01, 71.89it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████▎             | 404/500 [00:06<00:01, 72.92it/s]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████▌            | 412/500 [00:06<00:01, 64.43it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████▍           | 419/500 [00:06<00:01, 64.52it/s]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████▋          | 427/500 [00:06<00:01, 67.06it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████▊         | 435/500 [00:06<00:00, 68.89it/s]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████▊        | 442/500 [00:06<00:00, 60.42it/s]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████▊       | 449/500 [00:07<00:00, 60.09it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████▊      | 456/500 [00:07<00:00, 52.30it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████▌     | 462/500 [00:07<00:00, 51.57it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████████████████████████████████▌    | 469/500 [00:07<00:00, 54.85it/s]\u001b[A\n",
      " 95%|███████████████████████████████████████████████████████████████████▌   | 476/500 [00:07<00:00, 55.74it/s]\u001b[A\n",
      " 97%|████████████████████████████████████████████████████████████████████▋  | 484/500 [00:07<00:00, 60.97it/s]\u001b[A\n",
      " 98%|█████████████████████████████████████████████████████████████████████▋ | 491/500 [00:07<00:00, 61.47it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████▋| 498/500 [00:07<00:00, 62.83it/s]\u001b[A\n",
      "                                                                                                              \u001b[A2022-10-18 15:31:52.337 | INFO     | __main__:<module>:41 - [2/100] | BestAcc: 41.170 | TrainLoss: 2.03 | TrainAcc: 29.73 | curr_val_acc=41.17\n",
      "[2/100] | BestAcc: 41.170 | TrainLoss: 2.03 | TrainAcc: 29.73:   2%| | 2/100 [00:30<23:44, 14.53s/epochs, trai\n",
      "  0%|                                                                                 | 0/500 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▏                                                                        | 1/500 [00:00<01:24,  5.88it/s]\u001b[A\n",
      "  2%|█▎                                                                       | 9/500 [00:00<00:13, 37.76it/s]\u001b[A\n",
      "  3%|██▍                                                                     | 17/500 [00:00<00:09, 51.49it/s]\u001b[A\n",
      "  5%|███▍                                                                    | 24/500 [00:00<00:08, 56.51it/s]\u001b[A\n",
      "  6%|████▍                                                                   | 31/500 [00:00<00:08, 57.06it/s]\u001b[A\n",
      "  8%|█████▍                                                                  | 38/500 [00:00<00:07, 59.90it/s]\u001b[A\n",
      "  9%|██████▌                                                                 | 46/500 [00:00<00:07, 64.12it/s]\u001b[A\n",
      " 11%|███████▊                                                                | 54/500 [00:00<00:06, 67.52it/s]\u001b[A\n",
      " 12%|████████▉                                                               | 62/500 [00:01<00:06, 69.55it/s]\u001b[A\n",
      " 14%|██████████                                                              | 70/500 [00:01<00:06, 71.09it/s]\u001b[A\n",
      " 16%|███████████▏                                                            | 78/500 [00:01<00:06, 66.35it/s]\u001b[A\n",
      " 17%|████████████▏                                                           | 85/500 [00:01<00:06, 63.48it/s]\u001b[A\n",
      " 18%|█████████████▏                                                          | 92/500 [00:01<00:06, 64.92it/s]\u001b[A\n",
      " 20%|██████████████▎                                                         | 99/500 [00:01<00:06, 66.24it/s]\u001b[A\n",
      " 21%|███████████████                                                        | 106/500 [00:01<00:05, 67.10it/s]\u001b[A\n",
      " 23%|████████████████▏                                                      | 114/500 [00:01<00:05, 68.11it/s]\u001b[A\n",
      " 24%|█████████████████▏                                                     | 121/500 [00:01<00:05, 66.26it/s]\u001b[A\n",
      " 26%|██████████████████▏                                                    | 128/500 [00:02<00:05, 63.67it/s]\u001b[A\n",
      " 27%|███████████████████▏                                                   | 135/500 [00:02<00:05, 62.92it/s]\u001b[A\n",
      " 28%|████████████████████▏                                                  | 142/500 [00:02<00:05, 64.46it/s]\u001b[A\n",
      " 30%|█████████████████████▏                                                 | 149/500 [00:02<00:05, 60.55it/s]\u001b[A\n",
      " 31%|██████████████████████▏                                                | 156/500 [00:02<00:05, 61.04it/s]\u001b[A\n",
      " 33%|███████████████████████▎                                               | 164/500 [00:02<00:05, 63.94it/s]\u001b[A\n",
      " 34%|████████████████████████▎                                              | 171/500 [00:02<00:05, 60.21it/s]\u001b[A\n",
      " 36%|█████████████████████████▎                                             | 178/500 [00:02<00:05, 57.00it/s]\u001b[A\n",
      " 37%|██████████████████████████▍                                            | 186/500 [00:03<00:05, 60.90it/s]\u001b[A\n",
      " 39%|███████████████████████████▌                                           | 194/500 [00:03<00:04, 63.82it/s]\u001b[A\n",
      " 40%|████████████████████████████▌                                          | 201/500 [00:03<00:04, 65.27it/s]\u001b[A\n",
      " 42%|█████████████████████████████▋                                         | 209/500 [00:03<00:04, 66.95it/s]\u001b[A\n",
      " 43%|██████████████████████████████▋                                        | 216/500 [00:03<00:04, 62.05it/s]\u001b[A\n",
      " 45%|███████████████████████████████▋                                       | 223/500 [00:03<00:04, 57.24it/s]\u001b[A\n",
      " 46%|████████████████████████████████▊                                      | 231/500 [00:03<00:04, 61.73it/s]\u001b[A\n",
      " 48%|█████████████████████████████████▉                                     | 239/500 [00:03<00:03, 65.71it/s]\u001b[A\n",
      " 49%|███████████████████████████████████                                    | 247/500 [00:03<00:03, 68.02it/s]\u001b[A\n",
      " 51%|████████████████████████████████████▏                                  | 255/500 [00:04<00:03, 70.68it/s]\u001b[A\n",
      " 53%|█████████████████████████████████████▎                                 | 263/500 [00:04<00:03, 71.49it/s]\u001b[A\n",
      " 54%|██████████████████████████████████████▍                                | 271/500 [00:04<00:03, 71.44it/s]\u001b[A\n",
      " 56%|███████████████████████████████████████▌                               | 279/500 [00:04<00:03, 69.80it/s]\u001b[A\n",
      " 57%|████████████████████████████████████████▊                              | 287/500 [00:04<00:03, 70.08it/s]\u001b[A\n",
      " 59%|█████████████████████████████████████████▉                             | 295/500 [00:04<00:02, 71.16it/s]\u001b[A\n",
      " 61%|███████████████████████████████████████████                            | 303/500 [00:04<00:02, 72.48it/s]\u001b[A\n",
      " 62%|████████████████████████████████████████████▏                          | 311/500 [00:04<00:02, 73.59it/s]\u001b[A\n",
      " 64%|█████████████████████████████████████████████▎                         | 319/500 [00:04<00:02, 69.50it/s]\u001b[A\n",
      " 65%|██████████████████████████████████████████████▍                        | 327/500 [00:05<00:02, 66.02it/s]\u001b[A\n",
      " 67%|███████████████████████████████████████████████▌                       | 335/500 [00:05<00:02, 68.23it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████▋                      | 343/500 [00:05<00:02, 70.00it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████▊                     | 351/500 [00:05<00:02, 71.52it/s]\u001b[A\n",
      " 72%|██████████████████████████████████████████████████▉                    | 359/500 [00:05<00:01, 73.09it/s]\u001b[A\n",
      " 73%|████████████████████████████████████████████████████                   | 367/500 [00:05<00:01, 74.46it/s]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████▎                 | 375/500 [00:05<00:01, 66.66it/s]\u001b[A\n",
      " 76%|██████████████████████████████████████████████████████▏                | 382/500 [00:05<00:01, 66.22it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████▍               | 390/500 [00:05<00:01, 68.41it/s]\u001b[A\n",
      " 80%|████████████████████████████████████████████████████████▌              | 398/500 [00:06<00:01, 69.94it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████▋             | 406/500 [00:06<00:01, 71.47it/s]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████▊            | 414/500 [00:06<00:01, 72.51it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████▉           | 422/500 [00:06<00:01, 69.34it/s]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████▉          | 429/500 [00:06<00:01, 64.60it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████▉         | 436/500 [00:06<00:00, 65.54it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████████████████████████████▉        | 443/500 [00:06<00:00, 65.89it/s]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████▉       | 450/500 [00:06<00:00, 65.77it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████      | 458/500 [00:06<00:00, 68.88it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████████████████████████████████▏    | 466/500 [00:07<00:00, 70.89it/s]\u001b[A\n",
      " 95%|███████████████████████████████████████████████████████████████████▎   | 474/500 [00:07<00:00, 67.08it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████▎  | 481/500 [00:07<00:00, 62.86it/s]\u001b[A\n",
      " 98%|█████████████████████████████████████████████████████████████████████▍ | 489/500 [00:07<00:00, 66.50it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████████████████████████████████▍| 496/500 [00:07<00:00, 65.70it/s]\u001b[A\n",
      "                                                                                                              \u001b[A2022-10-18 15:32:02.208 | INFO     | __main__:<module>:41 - [3/100] | BestAcc: 41.170 | TrainLoss: 2.00 | TrainAcc: 31.37 | curr_val_acc=40.99\n",
      "[3/100] | BestAcc: 41.170 | TrainLoss: 2.00 | TrainAcc: 31.37:   3%| | 3/100 [00:40<20:03, 12.40s/epochs, trai\n",
      "  0%|                                                                                 | 0/500 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▏                                                                        | 1/500 [00:00<01:35,  5.23it/s]\u001b[A\n",
      "  1%|▉                                                                        | 6/500 [00:00<00:21, 23.25it/s]\u001b[A\n",
      "  3%|█▊                                                                      | 13/500 [00:00<00:12, 39.82it/s]\u001b[A\n",
      "  4%|███                                                                     | 21/500 [00:00<00:09, 51.70it/s]\u001b[A\n",
      "  6%|████▏                                                                   | 29/500 [00:00<00:07, 58.94it/s]\u001b[A\n",
      "  7%|█████▎                                                                  | 37/500 [00:00<00:07, 63.22it/s]\u001b[A\n",
      "  9%|██████▍                                                                 | 45/500 [00:00<00:06, 65.77it/s]\u001b[A\n",
      " 10%|███████▍                                                                | 52/500 [00:00<00:07, 61.14it/s]\u001b[A\n",
      " 12%|████████▍                                                               | 59/500 [00:01<00:07, 60.92it/s]\u001b[A\n",
      " 13%|█████████▋                                                              | 67/500 [00:01<00:06, 63.73it/s]\u001b[A\n",
      " 15%|██████████▊                                                             | 75/500 [00:01<00:06, 66.24it/s]\u001b[A\n",
      " 17%|███████████▉                                                            | 83/500 [00:01<00:06, 68.15it/s]\u001b[A\n",
      " 18%|█████████████                                                           | 91/500 [00:01<00:05, 69.43it/s]\u001b[A\n",
      " 20%|██████████████                                                          | 98/500 [00:01<00:06, 66.73it/s]\u001b[A\n",
      " 21%|██████████████▉                                                        | 105/500 [00:01<00:06, 63.34it/s]\u001b[A\n",
      " 22%|███████████████▉                                                       | 112/500 [00:01<00:06, 64.35it/s]\u001b[A\n",
      " 24%|█████████████████                                                      | 120/500 [00:01<00:05, 67.28it/s]\u001b[A\n",
      " 26%|██████████████████▏                                                    | 128/500 [00:02<00:05, 68.57it/s]\u001b[A\n",
      " 27%|███████████████████▎                                                   | 136/500 [00:02<00:05, 69.74it/s]\u001b[A\n",
      " 29%|████████████████████▎                                                  | 143/500 [00:02<00:05, 69.16it/s]\u001b[A\n",
      " 30%|█████████████████████▍                                                 | 151/500 [00:02<00:05, 69.79it/s]\u001b[A\n",
      " 32%|██████████████████████▍                                                | 158/500 [00:02<00:05, 65.45it/s]\u001b[A\n",
      " 33%|███████████████████████▌                                               | 166/500 [00:02<00:04, 67.51it/s]\u001b[A\n",
      " 35%|████████████████████████▋                                              | 174/500 [00:02<00:04, 69.69it/s]\u001b[A\n",
      " 36%|█████████████████████████▊                                             | 182/500 [00:02<00:04, 71.19it/s]\u001b[A\n",
      " 38%|██████████████████████████▉                                            | 190/500 [00:02<00:04, 71.60it/s]\u001b[A\n",
      " 40%|████████████████████████████                                           | 198/500 [00:03<00:04, 70.91it/s]\u001b[A\n",
      " 41%|█████████████████████████████▎                                         | 206/500 [00:03<00:04, 64.35it/s]\u001b[A\n",
      " 43%|██████████████████████████████▏                                        | 213/500 [00:03<00:04, 65.47it/s]\u001b[A\n",
      " 44%|███████████████████████████████▍                                       | 221/500 [00:03<00:04, 67.94it/s]\u001b[A\n",
      " 46%|████████████████████████████████▌                                      | 229/500 [00:03<00:03, 69.93it/s]\u001b[A\n",
      " 47%|█████████████████████████████████▋                                     | 237/500 [00:03<00:03, 71.96it/s]\u001b[A\n",
      " 49%|██████████████████████████████████▊                                    | 245/500 [00:03<00:03, 72.94it/s]\u001b[A\n",
      " 51%|███████████████████████████████████▉                                   | 253/500 [00:03<00:03, 67.34it/s]\u001b[A\n",
      " 52%|████████████████████████████████████▉                                  | 260/500 [00:04<00:03, 63.87it/s]\u001b[A\n",
      " 54%|██████████████████████████████████████                                 | 268/500 [00:04<00:03, 66.26it/s]\u001b[A\n",
      " 55%|███████████████████████████████████████▏                               | 276/500 [00:04<00:03, 69.18it/s]\u001b[A\n",
      " 57%|████████████████████████████████████████▎                              | 284/500 [00:04<00:03, 71.21it/s]\u001b[A\n",
      " 58%|█████████████████████████████████████████▍                             | 292/500 [00:04<00:02, 71.36it/s]\u001b[A\n",
      " 60%|██████████████████████████████████████████▌                            | 300/500 [00:04<00:02, 71.80it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████▋                           | 308/500 [00:04<00:02, 71.59it/s]\u001b[A\n",
      " 63%|████████████████████████████████████████████▊                          | 316/500 [00:04<00:02, 71.78it/s]\u001b[A\n",
      " 65%|██████████████████████████████████████████████                         | 324/500 [00:04<00:02, 72.86it/s]\u001b[A\n",
      " 66%|███████████████████████████████████████████████▏                       | 332/500 [00:05<00:02, 72.82it/s]\u001b[A\n",
      " 68%|████████████████████████████████████████████████▎                      | 340/500 [00:05<00:02, 73.01it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████▍                     | 348/500 [00:05<00:02, 72.92it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████▌                    | 356/500 [00:05<00:01, 72.39it/s]\u001b[A\n",
      " 73%|███████████████████████████████████████████████████▋                   | 364/500 [00:05<00:01, 71.18it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████▊                  | 372/500 [00:05<00:01, 70.61it/s]\u001b[A\n",
      " 76%|█████████████████████████████████████████████████████▉                 | 380/500 [00:05<00:01, 71.31it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████                | 388/500 [00:05<00:01, 72.10it/s]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████▏              | 396/500 [00:05<00:01, 72.17it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████▎             | 404/500 [00:06<00:01, 73.12it/s]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████▌            | 412/500 [00:06<00:01, 68.85it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████▍           | 419/500 [00:06<00:01, 63.71it/s]\u001b[A\n",
      " 85%|████████████████████████████████████████████████████████████▍          | 426/500 [00:06<00:01, 62.96it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████▍         | 433/500 [00:06<00:01, 64.06it/s]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████▍        | 440/500 [00:06<00:00, 63.93it/s]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████▌       | 448/500 [00:06<00:00, 65.99it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████▌      | 455/500 [00:06<00:00, 66.62it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████▌     | 462/500 [00:06<00:00, 62.35it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████████████████████████████████▌    | 469/500 [00:07<00:00, 62.22it/s]\u001b[A\n",
      " 95%|███████████████████████████████████████████████████████████████████▋   | 477/500 [00:07<00:00, 65.35it/s]\u001b[A\n",
      " 97%|████████████████████████████████████████████████████████████████████▊  | 485/500 [00:07<00:00, 68.32it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████████████████████████████████ | 493/500 [00:07<00:00, 68.10it/s]\u001b[A\n",
      "                                                                                                              \u001b[A2022-10-18 15:32:12.055 | INFO     | __main__:<module>:41 - [4/100] | BestAcc: 43.370 | TrainLoss: 1.99 | TrainAcc: 32.66 | curr_val_acc=43.37\n",
      "[4/100] | BestAcc: 43.370 | TrainLoss: 1.99 | TrainAcc: 32.66:   4%| | 4/100 [00:50<18:13, 11.39s/epochs, trai\n",
      "  0%|                                                                                 | 0/500 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▏                                                                        | 1/500 [00:00<02:00,  4.14it/s]\u001b[A\n",
      "  2%|█▎                                                                       | 9/500 [00:00<00:15, 30.92it/s]\u001b[A\n",
      "  3%|██▍                                                                     | 17/500 [00:00<00:10, 46.42it/s]\u001b[A\n",
      "  5%|███▌                                                                    | 25/500 [00:00<00:08, 55.97it/s]\u001b[A\n",
      "  7%|████▊                                                                   | 33/500 [00:00<00:07, 61.91it/s]\u001b[A\n",
      "  8%|█████▊                                                                  | 40/500 [00:00<00:07, 60.44it/s]\u001b[A\n",
      "  9%|██████▊                                                                 | 47/500 [00:00<00:07, 58.67it/s]\u001b[A\n",
      " 11%|███████▉                                                                | 55/500 [00:01<00:07, 63.37it/s]\u001b[A\n",
      " 13%|█████████                                                               | 63/500 [00:01<00:06, 67.17it/s]\u001b[A\n",
      " 14%|██████████▏                                                             | 71/500 [00:01<00:06, 70.19it/s]\u001b[A\n",
      " 16%|███████████▍                                                            | 79/500 [00:01<00:05, 72.25it/s]\u001b[A\n",
      " 17%|████████████▌                                                           | 87/500 [00:01<00:05, 73.25it/s]\u001b[A\n",
      " 19%|█████████████▋                                                          | 95/500 [00:01<00:05, 68.57it/s]\u001b[A\n",
      " 20%|██████████████▍                                                        | 102/500 [00:01<00:05, 66.53it/s]\u001b[A\n",
      " 22%|███████████████▌                                                       | 110/500 [00:01<00:05, 69.55it/s]\u001b[A\n",
      " 24%|████████████████▊                                                      | 118/500 [00:01<00:05, 70.98it/s]\u001b[A\n",
      " 25%|█████████████████▉                                                     | 126/500 [00:02<00:05, 72.45it/s]\u001b[A\n",
      " 27%|███████████████████                                                    | 134/500 [00:02<00:05, 72.60it/s]\u001b[A\n",
      " 28%|████████████████████▏                                                  | 142/500 [00:02<00:04, 72.62it/s]\u001b[A\n",
      " 30%|█████████████████████▎                                                 | 150/500 [00:02<00:04, 71.10it/s]\u001b[A\n",
      " 32%|██████████████████████▍                                                | 158/500 [00:02<00:04, 70.77it/s]\u001b[A\n",
      " 33%|███████████████████████▌                                               | 166/500 [00:02<00:04, 70.59it/s]\u001b[A\n",
      " 35%|████████████████████████▋                                              | 174/500 [00:02<00:04, 71.12it/s]\u001b[A\n",
      " 36%|█████████████████████████▊                                             | 182/500 [00:02<00:04, 72.50it/s]\u001b[A\n",
      " 38%|██████████████████████████▉                                            | 190/500 [00:02<00:04, 73.21it/s]\u001b[A\n",
      " 40%|████████████████████████████                                           | 198/500 [00:03<00:04, 72.09it/s]\u001b[A\n",
      " 41%|█████████████████████████████▎                                         | 206/500 [00:03<00:04, 67.42it/s]\u001b[A\n",
      " 43%|██████████████████████████████▏                                        | 213/500 [00:03<00:04, 67.78it/s]\u001b[A\n",
      " 44%|███████████████████████████████▍                                       | 221/500 [00:03<00:04, 69.72it/s]\u001b[A\n",
      " 46%|████████████████████████████████▌                                      | 229/500 [00:03<00:03, 70.58it/s]\u001b[A\n",
      " 47%|█████████████████████████████████▋                                     | 237/500 [00:03<00:03, 72.02it/s]\u001b[A\n",
      " 49%|██████████████████████████████████▊                                    | 245/500 [00:03<00:03, 73.70it/s]\u001b[A\n",
      " 51%|███████████████████████████████████▉                                   | 253/500 [00:03<00:03, 69.73it/s]\u001b[A\n",
      " 52%|█████████████████████████████████████                                  | 261/500 [00:03<00:03, 66.46it/s]\u001b[A\n",
      " 54%|██████████████████████████████████████▏                                | 269/500 [00:04<00:03, 69.23it/s]\u001b[A\n",
      " 55%|███████████████████████████████████████▎                               | 277/500 [00:04<00:03, 71.36it/s]\u001b[A\n",
      " 57%|████████████████████████████████████████▍                              | 285/500 [00:04<00:02, 73.68it/s]\u001b[A\n",
      " 59%|█████████████████████████████████████████▌                             | 293/500 [00:04<00:02, 74.90it/s]\u001b[A\n",
      " 60%|██████████████████████████████████████████▋                            | 301/500 [00:04<00:02, 75.59it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████▉                           | 309/500 [00:04<00:02, 72.51it/s]\u001b[A\n",
      " 63%|█████████████████████████████████████████████                          | 317/500 [00:04<00:02, 69.04it/s]\u001b[A\n",
      " 65%|██████████████████████████████████████████████▏                        | 325/500 [00:04<00:02, 70.30it/s]\u001b[A\n",
      " 67%|███████████████████████████████████████████████▎                       | 333/500 [00:04<00:02, 70.80it/s]\u001b[A\n",
      " 68%|████████████████████████████████████████████████▍                      | 341/500 [00:05<00:02, 71.35it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████▌                     | 349/500 [00:05<00:02, 72.02it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████▋                    | 357/500 [00:05<00:02, 70.94it/s]\u001b[A\n",
      " 73%|███████████████████████████████████████████████████▊                   | 365/500 [00:05<00:01, 70.38it/s]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████▉                  | 373/500 [00:05<00:01, 69.11it/s]\u001b[A\n",
      " 76%|██████████████████████████████████████████████████████                 | 381/500 [00:05<00:01, 70.05it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████▏               | 389/500 [00:05<00:01, 71.31it/s]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████▎              | 397/500 [00:05<00:01, 71.54it/s]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████▌             | 405/500 [00:05<00:01, 71.84it/s]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████▋            | 413/500 [00:06<00:01, 71.27it/s]\u001b[A\n",
      " 84%|███████████████████████████████████████████████████████████▊           | 421/500 [00:06<00:01, 71.80it/s]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████▉          | 429/500 [00:06<00:00, 73.55it/s]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████         | 437/500 [00:06<00:00, 74.63it/s]\u001b[A\n",
      " 89%|███████████████████████████████████████████████████████████████▏       | 445/500 [00:06<00:00, 74.69it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████▎      | 453/500 [00:06<00:00, 75.61it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████▍     | 461/500 [00:06<00:00, 76.50it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████████████████████████████████▌    | 469/500 [00:06<00:00, 75.38it/s]\u001b[A\n",
      " 95%|███████████████████████████████████████████████████████████████████▋   | 477/500 [00:06<00:00, 74.83it/s]\u001b[A\n",
      " 97%|████████████████████████████████████████████████████████████████████▊  | 485/500 [00:07<00:00, 74.67it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████████████████████████████████ | 493/500 [00:07<00:00, 72.61it/s]\u001b[A\n",
      "[4/100] | BestAcc: 43.370 | TrainLoss: 1.99 | TrainAcc: 32.66:   4%| | 4/100 [00:58<23:12, 14.50s/epochs, trai\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m     24\u001b[0m     state, train_loss, train_acc \u001b[38;5;241m=\u001b[39m train_epoch(state, train_dl, epoch)\n\u001b[0;32m---> 25\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m eval_model(state, eval_dl)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m test_acc \u001b[38;5;241m>\u001b[39m ckpt_tracker\u001b[38;5;241m.\u001b[39mbest_acc:\n\u001b[1;32m     27\u001b[0m         old_ckpt_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(logdir \u001b[38;5;241m/\u001b[39m ckpt_tracker\u001b[38;5;241m.\u001b[39mget_save_name())\n",
      "Cell \u001b[0;32mIn [4], line 106\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(state, test_dl)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_model\u001b[39m(state, test_dl):\n\u001b[1;32m    104\u001b[0m     batch_metrics \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_dl):\n\u001b[1;32m    107\u001b[0m         batch \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: jnp\u001b[38;5;241m.\u001b[39marray(batch[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: jnp\u001b[38;5;241m.\u001b[39marray(batch[\u001b[38;5;241m1\u001b[39m])}\n\u001b[1;32m    109\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m eval_step(state, batch)\n",
      "File \u001b[0;32m~/miniconda3/envs/hamux/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/hamux/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hamux/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1327\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/hamux/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hamux/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/envs/hamux/lib/python3.9/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hamux/lib/python3.9/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/hamux/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/hamux/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "## Training\n",
    "# ===========================================\n",
    "@dataclass\n",
    "class CkptTracker:\n",
    "    base_name: str\n",
    "    model: tx.Module = None\n",
    "    epoch: int = -1\n",
    "    best_acc: float = -1\n",
    "\n",
    "    def get_save_name(self):\n",
    "        return f\"{self.base_name}_epoch-{self.epoch}_acc-{100*self.best_acc:.3f}.pckl\"\n",
    "\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "ckpt_tracker = CkptTracker(\"DummyCifar\")\n",
    "logdir = Path(\"./_logs\")\n",
    "logdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "with trange(1, num_epochs + 1, unit=\"epochs\") as pbar:\n",
    "    for epoch in pbar:\n",
    "        state, train_loss, train_acc = train_epoch(state, train_dl, epoch)\n",
    "        test_loss, test_acc = eval_model(state, eval_dl)\n",
    "        if test_acc > ckpt_tracker.best_acc:\n",
    "            old_ckpt_name = str(logdir / ckpt_tracker.get_save_name())\n",
    "            try:\n",
    "                os.remove(old_ckpt_name)\n",
    "            except Exception as e:\n",
    "                logger.debug(f\"Couldn't remove {old_ckpt_name}, {e}\")\n",
    "                pass\n",
    "            ckpt_tracker.model = state.model\n",
    "            ckpt_tracker.epoch = epoch\n",
    "            ckpt_tracker.best_acc = test_acc\n",
    "            to_save = jtu.tree_map(hmx.utils.to_pickleable, ckpt_tracker.model.to_dict())\n",
    "            ckpt_name = str(logdir / ckpt_tracker.get_save_name())\n",
    "            hmx.utils.pytree_save(to_save, ckpt_name, overwrite=True)\n",
    "        desc = f\"[{epoch}/{num_epochs}] | BestAcc: {100*ckpt_tracker.best_acc:.3f} | TrainLoss: {train_loss:.2f} | TrainAcc: {100*train_acc:.2f}\"\n",
    "        addition = f\"curr_val_acc={100*test_acc:0.2f}\"\n",
    "        logger.info(desc + \" | \" + addition)\n",
    "        pbar.set_description(desc)\n",
    "        pbar.set_postfix(\n",
    "            train_acc=f\"{100*train_acc:0.2f}\", val_acc=f\"{100*test_acc:0.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba7898-19a8-491b-94d5-2dd5ad728223",
   "metadata": {},
   "source": [
    "Brief analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5398c4-3152-4701-a5da-e50c16d9ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_energy(model, x, depth=4, dt=1, rng=None):\n",
    "    \"\"\"A pure function to extract desired information from the configured HAM, applied on batched inputs\"\"\"\n",
    "    # Initialize hidden states to our image\n",
    "    xs = model.init_states(x.shape[0], rng=rng)\n",
    "    xs[0] = jnp.array(rearrange(x, \"... c h w -> ... (c h w)\"))\n",
    "\n",
    "    # Masks allow us to clamp our visible data over time\n",
    "    masks = jtu.tree_map(lambda x: jnp.ones_like(x, dtype=jnp.int8), xs)\n",
    "    # masks[0] = jnp.zeros_like(masks[0], dtype=jnp.int8)  # Don't evolve images\n",
    "    all_xs = [xs]\n",
    "    energies = [model.venergy(xs)]\n",
    "\n",
    "    for i in range(depth):\n",
    "        updates = model.vupdates(xs)  # Calculate the updates\n",
    "        xs = model.step(\n",
    "            xs, updates, dt=dt, masks=masks\n",
    "        )  # Add them to our current states\n",
    "        all_xs.append(xs)\n",
    "        energies.append(model.venergy(xs))\n",
    "\n",
    "    # All labels have a softmax activation function as the last layer, spitting out probabilities\n",
    "    return jnp.stack(energies), all_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54725f1-a671-4ed5-bae2-8278d811ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_start = batch[0][:1]\n",
    "# img_start = jnp.ones_like(jnp.array(img_start))\n",
    "energies, allxs = fwd_energy(ham, img_start, dt=0.2, depth=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa204c07-db8f-4201-a21e-7a5b62327450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "def show_x(x):\n",
    "    x = rearrange(x, \"... (c h w) -> ... c h w\", c=3, h=32, w=32)\n",
    "    return data_config.show(torch.tensor(np.array(x)))\n",
    "\n",
    "aa = make_grid([rearrange(torch.tensor(show_x(x[0][0])), \"h w c -> c h w\") for x in allxs])\n",
    "\n",
    "plt.imshow(np.array(rearrange(aa, \"c h w -> h w c\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b1ad7-d01e-4a94-987c-0423b5c27be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c08e34b-f2fc-4f83-bdbf-1cd05199f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_start = batch[0][:1]\n",
    "# img_start = jnp.ones_like(jnp.array(img_start))\n",
    "# # energies, allxs = fwd_energy(ham, img_start, dt=0.1, depth=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hamux]",
   "language": "python",
   "name": "conda-env-hamux-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
