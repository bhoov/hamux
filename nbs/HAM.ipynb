{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ceb168-3a83-4fe7-aa89-8ed76107b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8414905-9daf-4f04-87fc-50a13e0d8138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83426342-2bd5-48ac-b084-a4c986e5241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import treex as tx\n",
    "from einops import rearrange\n",
    "from flax import linen as nn\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import *\n",
    "from dataclasses import dataclass\n",
    "import optax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.tree_util as jtu\n",
    "from hamux.utils import pytree_load, pytree_save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d635a-a8a3-4b00-a081-0c4b3b1ce260",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HAM Energy Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51685a5b-ab15-4eac-bbfb-2ce8bad60f77",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lagrangians\n",
    "\n",
    "Because lagrangian functions of common activation functions can be used in both layers and synapses, it is helpful to define the operations outside the classes in which they operate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7fc6f5b-1403-4ab5-988d-27e3dac27ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LIdentity(x):\n",
    "    return 1/2 * jnp.power(x, 2).sum()\n",
    "\n",
    "def LRelu(x):\n",
    "    return 1/2 * jnp.power(jnp.maximum(x, 0), 2).sum()\n",
    "\n",
    "def LSoftmax(x, beta=1., axis=-1):\n",
    "    return 1/beta * jax.nn.logsumexp(beta * x, axis=axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47cbac-61e6-4206-b121-167515509350",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecdb977e-e555-4c6e-8136-19be9fbd9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(tx.Module, ABC):\n",
    "    shape: Tuple\n",
    "    \n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        \n",
    "    @abstractmethod\n",
    "    def lagrangian(self, x):\n",
    "        pass\n",
    "    \n",
    "    def activation(self, x):\n",
    "        return self.g(x)\n",
    "    \n",
    "    def energy(self, x):\n",
    "        \n",
    "        # When jitted, this is no slower than the optimized `@` vector multiplication\n",
    "        # This is also more universal in case `x` is not a vector\n",
    "        return jnp.multiply(self.g(x), x).sum() - self.lagrangian(x) \n",
    "    \n",
    "    def g(self, x):\n",
    "        return jax.grad(self.lagrangian)(x)\n",
    "    \n",
    "    def init_state(self, bs:int=None):\n",
    "        if bs is not None:\n",
    "            return jnp.zeros((bs, *self.shape))\n",
    "        return jnp.zeros(self.shape)\n",
    "    \n",
    "class IdentityLayer(Layer):\n",
    "    def lagrangian(self, x):\n",
    "        return LIdentity(x)\n",
    "    \n",
    "class RELULayer(Layer):\n",
    "    def lagrangian(self, x):\n",
    "        return LRelu(x)\n",
    "    \n",
    "class SoftmaxLayer(Layer):\n",
    "    beta: jnp.ndarray = tx.Parameter.node(default=jnp.array(1.))\n",
    "    \n",
    "    def lagrangian(self, x):\n",
    "        return LSoftmax(x, self.beta.clip(1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3485a74d-764e-43a1-ac0a-0a3d3223a39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity: [0. 1. 2. 3. 4. 5. 6. 7. 8.]\n",
      "RELU: [0. 0. 0. 0. 0. 0. 1. 2. 3.])\n",
      "Softmax: [2.1207899e-04 5.7649048e-04 1.5670636e-03 4.2597204e-03 1.1579121e-02\n",
      " 3.1475313e-02 8.5558772e-02 2.3257288e-01 6.3219857e-01])\n"
     ]
    }
   ],
   "source": [
    "layer = IdentityLayer((9,))\n",
    "x = jnp.arange(9, dtype=jnp.float32)\n",
    "print(f\"Identity: {layer.g(x)}\")\n",
    "\n",
    "layer = RELULayer((9,))\n",
    "x = jnp.arange(9, dtype=jnp.float32) - 5\n",
    "print(f\"RELU: {layer.g(x)})\")\n",
    "\n",
    "layer = SoftmaxLayer((9,))\n",
    "x = jnp.arange(9, dtype=jnp.float32) - 2\n",
    "print(f\"Softmax: {layer.g(x)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b39fe7-0716-4224-8711-e3dbe8c64d37",
   "metadata": {},
   "source": [
    "## Synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2868c466-a412-4992-a2df-4a9da1dfda82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synapse(tx.Module, ABC):\n",
    "    @abstractmethod\n",
    "    def energy(self, *gs):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, *gs):\n",
    "        return self.energy(*gs)\n",
    "\n",
    "class DenseSynapse(Synapse):\n",
    "    stdinit:float = 0.02\n",
    "    weight: jnp.ndarray = tx.Parameter.node()\n",
    "        \n",
    "    def energy(self, g1, g2):\n",
    "        if self.initializing():\n",
    "            key = tx.next_key() \n",
    "            self.weight = nn.initializers.normal(self.stdinit)(key, (g1.shape[0], g2.shape[0]))\n",
    "        return -g1 @ self.weight @ g2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e1a5ba0-f12e-4ad5-a010-63902378ac23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(-15.429065, dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin, fout = 44, 33\n",
    "g1 = jnp.arange(fin)\n",
    "g2 = jnp.ones(fout)\n",
    "synapse = DenseSynapse().init(key=jax.random.PRNGKey(5), inputs=(g1, g2))\n",
    "synapse.energy(g1, g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbdec70-6242-45f0-a0c0-9b43d155277c",
   "metadata": {},
   "source": [
    "## HAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54ebc057-a1d9-45c2-81ed-27c984b84d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAM(tx.Module):\n",
    "    layers: List[Layer]\n",
    "    synapses: List[Synapse]\n",
    "    connections: List[Tuple[Tuple, int]]\n",
    "\n",
    "    def __init__(self, layers, synapses, connections):\n",
    "        self.layers = layers\n",
    "        self.synapses = synapses\n",
    "        self.connections = connections\n",
    "    \n",
    "    @property\n",
    "    def n_layers(self):\n",
    "        return len(self.layers)\n",
    "    \n",
    "    @property\n",
    "    def n_synapses(self):\n",
    "        return len(self.synapses)\n",
    "    \n",
    "    @property\n",
    "    def n_connections(self):\n",
    "        return len(self.connections)\n",
    "    \n",
    "    def layer_energy(self, states):\n",
    "        energies = jnp.stack([\n",
    "            self.layers[i].energy(x) for i, x in enumerate(states)\n",
    "        ])\n",
    "        return jnp.sum(energies)\n",
    "    \n",
    "    def synapse_energy(self, states):\n",
    "        def get_energy(lset, k):\n",
    "            gs = [self.layers[i].g(states[i]) for i in lset]\n",
    "            synapse = self.synapses[k]\n",
    "            return synapse(*gs)\n",
    "\n",
    "        energies = jnp.stack([\n",
    "            get_energy(lset, k) for lset,k in self.connections\n",
    "        ])\n",
    "        return jnp.sum(energies)\n",
    "    \n",
    "    def energy(self, states):\n",
    "        energy = self.layer_energy(states) + self.synapse_energy(states)\n",
    "        return energy\n",
    "    \n",
    "    def venergy(self, states):\n",
    "        return jax.vmap(self.energy, in_axes=self._statelist_batch_axes())(states)\n",
    "    \n",
    "    def __call__(self, states):\n",
    "        return self.energy(states)\n",
    "    \n",
    "    def grad(self, states):\n",
    "        return jax.grad(self.energy)(states)\n",
    "    \n",
    "    def vgrad(self, states):\n",
    "        return jax.vmap(self.grad, in_axes=self._statelist_batch_axes())(states)\n",
    "    \n",
    "    def _statelist_batch_axes(self):\n",
    "        return ([0 for _ in range(self.n_layers)],)\n",
    "    \n",
    "    def init_states(self, bs=None):\n",
    "        return [layer.init_state(bs) for layer in self.layers]\n",
    "    \n",
    "    def init_states_and_params(self, key, bs=None):\n",
    "        # params don't need a batch size to initialize\n",
    "        params = self.init(key, self.init_states(), call_method=\"energy\")\n",
    "        states = self.init_states(bs)\n",
    "        return states, params\n",
    "    \n",
    "    @classmethod\n",
    "    def load_from_state_dict(cls, outdict):\n",
    "        me = cls(outdict[\"layers\"], outdict[\"synapses\"], outdict[\"connections\"])\n",
    "        return me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77165f8b-22a4-43df-a5be-43c6699fcc89",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bfa96f-e4e0-4d5e-923a-5b8fd6460067",
   "metadata": {},
   "source": [
    "# Loading from lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb61024-d956-4699-b863-40621e046041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoo/miniconda3/envs/hamux/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from hamux.datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d981ef-c8fa-44ea-9286-5c67a455b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = DataloadingArgs(\n",
    "    dataset=\"torch/MNIST\",\n",
    "    aa=None,\n",
    "    reprob=0.0,\n",
    "    vflip=0.,\n",
    "    hflip=0.,\n",
    "    scale=(0.8,1.),\n",
    "    batch_size=10,\n",
    "    color_jitter=0.,\n",
    "    validation_batch_size=10_000,\n",
    ")\n",
    "data_config = DataConfigMNIST(input_size=(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91aa12ed-e66f-4126-8113-60f25800907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train, loader_eval = create_dataloaders(args, data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb70888c-bae9-42a4-bed1-3900447a18cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in loader_train:\n",
    "    imgs, labels = b\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "735de2d8-83f0-453e-95c9-4328e3d19028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efefb103a00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbfElEQVR4nO3df3DU9b3v8dfyIwtosjGE/FgJGFBB+REthTSjUpSUEOdyQZk5os4dcLxwscEpplYnPSradm5anLGOnhTmzLRQ5wha7hE4Oh16JZowaoJDhMswakpy0wKXJFSmyYYAIZDP+YPrtisE+l12885uno+Z7wzZ/X7yffN1xyffZPONzznnBADAABtmPQAAYGgiQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwMQI6wG+qa+vT8ePH1dqaqp8Pp/1OAAAj5xz6urqUjAY1LBh/V/nDLoAHT9+XHl5edZjAACu0dGjRzV+/Ph+nx90AUpNTZUk3a37NUIjjacBAHh1Xr36SL8P//+8P3ELUFVVlV5++WW1tbWpoKBAr7/+uubMmXPVdV9/2W2ERmqEjwABQML5/3cYvdq3UeLyJoS3335b5eXlWrdunT777DMVFBSopKREJ06ciMfhAAAJKC4BeuWVV7Ry5Uo99thjuv3227Vx40aNGTNGv/nNb+JxOABAAop5gM6dO6eGhgYVFxf/7SDDhqm4uFh1dXWX7N/T06NQKBSxAQCSX8wD9NVXX+nChQvKzs6OeDw7O1ttbW2X7F9ZWalAIBDeeAccAAwN5j+IWlFRoc7OzvB29OhR65EAAAMg5u+Cy8zM1PDhw9Xe3h7xeHt7u3Jyci7Z3+/3y+/3x3oMAMAgF/MroJSUFM2aNUvV1dXhx/r6+lRdXa2ioqJYHw4AkKDi8nNA5eXlWr58ub797W9rzpw5evXVV9Xd3a3HHnssHocDACSguATooYce0l/+8he98MILamtr0x133KFdu3Zd8sYEAMDQ5XPOOesh/l4oFFIgENA8LeZOCACQgM67XtVopzo7O5WWltbvfubvggMADE0ECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBEzAP04osvyufzRWxTp06N9WEAAAluRDw+6bRp07R79+6/HWREXA4DAEhgcSnDiBEjlJOTE49PDQBIEnH5HtDhw4cVDAY1adIkPfroozpy5Ei/+/b09CgUCkVsAIDkF/MAFRYWavPmzdq1a5c2bNiglpYW3XPPPerq6rrs/pWVlQoEAuEtLy8v1iMBAAYhn3POxfMAHR0dmjhxol555RU9/vjjlzzf09Ojnp6e8MehUEh5eXmap8Ua4RsZz9EAAHFw3vWqRjvV2dmptLS0fveL+7sD0tPTdeutt6qpqemyz/v9fvn9/niPAQAYZOL+c0CnTp1Sc3OzcnNz430oAEACiXmAnn76adXW1upPf/qTPvnkEz3wwAMaPny4Hn744VgfCgCQwGL+Jbhjx47p4Ycf1smTJzVu3Djdfffdqq+v17hx42J9KABAAot5gN56661Yf0oMcX133+F5TfN/Hx7Vse6fdsjzmj75ojrWQKg7flNU685/nOF5zYTfHfN+nD/1/yMaSH7cCw4AYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMBH3X0iH5OWbPcPzmqPfS/W85ntLP/W85p/TP/O8RpL+3/kbPK/5n4cWel4zsibgeU3o1gue19w+I7qbfd62rNHzmn+fdqfnNbcs52akQxlXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDB3bAh353Tolo3bP1Jz2vW3fgfntdUd9zueU3Zr1d7XiNJYz8/73lN3tFuz2uGHT7keU0wa6znNWcmBD2vkaRPxk7wvCbL74vqWBi6uAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwM1Ko8X9cF9W6/3XTJs9rHtnyA89rcj/2foPQiQ1NntdI0oX2E57XuGiOE8UahUKel4z4v0eiOZJGlnzL85q+EcOjOhaGLq6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3IwUeriwPqp1v2q/z/Oam/+lxfOa861tntdEdbPPZDRnWlTL8td96XnNl3/N8n6grd6XIHlwBQQAMEGAAAAmPAdoz549WrRokYLBoHw+n3bs2BHxvHNOL7zwgnJzczV69GgVFxfr8OHDsZoXAJAkPAeou7tbBQUFqqqquuzz69ev12uvvaaNGzdq7969uu6661RSUqKzZ89e87AAgOTh+U0IpaWlKi0tvexzzjm9+uqreu6557R48WJJ0htvvKHs7Gzt2LFDy5Ytu7ZpAQBJI6bfA2ppaVFbW5uKi4vDjwUCARUWFqquru6ya3p6ehQKhSI2AEDyi2mA2touvl02Ozs74vHs7Ozwc99UWVmpQCAQ3vLy8mI5EgBgkDJ/F1xFRYU6OzvD29GjR61HAgAMgJgGKCcnR5LU3t4e8Xh7e3v4uW/y+/1KS0uL2AAAyS+mAcrPz1dOTo6qq6vDj4VCIe3du1dFRUWxPBQAIMF5fhfcqVOn1NTUFP64paVFBw4cUEZGhiZMmKC1a9fqZz/7mW655Rbl5+fr+eefVzAY1JIlS2I5NwAgwXkO0L59+3TvvfeGPy4vL5ckLV++XJs3b9Yzzzyj7u5urVq1Sh0dHbr77ru1a9cujRo1KnZTAwASns8556yH+HuhUEiBQEDztFgjfCOtxxkS/ukL7zf7lKSNzXM9r8n4L3+M6liQ/ro8ii9j/9NXUR3r0zu3eV7zr51Bz2v+/bYobmCKQe+861WNdqqzs/OK39c3fxccAGBoIkAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAnPv44Byafq8HejWrfq5o88r3m9YrHnNXn/u9PzmmGnejyvidZfZ2V6XnNyus/zmkUlez2vWT72E89rLvL+61M2/NH73dGz9KXnNUgeXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GSk0assNUa079MPxntc8+d92el7zr0V3e15zpme05zXRmpF72POaqSPOeV6zp/Vmz2t2fFHgeY0kNd+3yfOaU194fx1leV6BZMIVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRQum7vohq3b4Rd3pe8/vCOzyvyZp80vOalBFnPK+J1r7PvN8kNP0L7//2yzzo/e+UceGC5zWSpPuiWDNh4M45kgNXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GCl3o6IxqXeDf6j2vuWFnquc1F6ZP8rxmIN1w8JDnNX3d3XGY5FLD09IG5DiS9F+nHPS8xvuZQzLhCggAYIIAAQBMeA7Qnj17tGjRIgWDQfl8Pu3YsSPi+RUrVsjn80VsCxcujNW8AIAk4TlA3d3dKigoUFVVVb/7LFy4UK2treFt69at1zQkACD5eH4TQmlpqUpLS6+4j9/vV05OTtRDAQCSX1y+B1RTU6OsrCxNmTJFTzzxhE6e7P9XKvf09CgUCkVsAIDkF/MALVy4UG+88Yaqq6v1i1/8QrW1tSotLdWFfn43fWVlpQKBQHjLy8uL9UgAgEEo5j8HtGzZsvCfZ8yYoZkzZ2ry5MmqqanR/PnzL9m/oqJC5eXl4Y9DoRARAoAhIO5vw540aZIyMzPV1NR02ef9fr/S0tIiNgBA8ot7gI4dO6aTJ08qNzc33ocCACQQz1+CO3XqVMTVTEtLiw4cOKCMjAxlZGTopZde0tKlS5WTk6Pm5mY988wzuvnmm1VSUhLTwQEAic1zgPbt26d77703/PHX379Zvny5NmzYoIMHD+q3v/2tOjo6FAwGtWDBAv30pz+V3++P3dQAgITnOUDz5s2Tc67f5//whz9c00BIbn1dXZ7X+Or+TxwmiZ0+6wGuJDtzwA41afRfPK85pLFxmASJgnvBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwETMfyU3gMHjr9/OGrBjvXP8Ts9rRuhIHCZBouAKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1IgSTWN8I3YMc6uu9Gz2vyuRnpkMYVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRAklsbH279QhAv7gCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNSIIl1zRhnPQLQL66AAAAmCBAAwISnAFVWVmr27NlKTU1VVlaWlixZosbGxoh9zp49q7KyMo0dO1bXX3+9li5dqvZ2ficJACCSpwDV1taqrKxM9fX1ev/999Xb26sFCxaou7s7vM9TTz2ld999V9u2bVNtba2OHz+uBx98MOaDAwASm6c3IezatSvi482bNysrK0sNDQ2aO3euOjs79etf/1pbtmzRfffdJ0natGmTbrvtNtXX1+s73/lO7CYHACS0a/oeUGdnpyQpIyNDktTQ0KDe3l4VFxeH95k6daomTJigurq6y36Onp4ehUKhiA0AkPyiDlBfX5/Wrl2ru+66S9OnT5cktbW1KSUlRenp6RH7Zmdnq62t7bKfp7KyUoFAILzl5eVFOxIAIIFEHaCysjIdOnRIb7311jUNUFFRoc7OzvB29OjRa/p8AIDEENUPoq5Zs0bvvfee9uzZo/Hjx4cfz8nJ0blz59TR0RFxFdTe3q6cnJzLfi6/3y+/3x/NGACABObpCsg5pzVr1mj79u364IMPlJ+fH/H8rFmzNHLkSFVXV4cfa2xs1JEjR1RUVBSbiQEAScHTFVBZWZm2bNminTt3KjU1Nfx9nUAgoNGjRysQCOjxxx9XeXm5MjIylJaWpieffFJFRUW8Aw4AEMFTgDZs2CBJmjdvXsTjmzZt0ooVKyRJv/zlLzVs2DAtXbpUPT09Kikp0a9+9auYDAsASB6eAuScu+o+o0aNUlVVlaqqqqIeCkBshPKGD9ixeseeH7BjITlwLzgAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYiOo3ogJIDFkNpwfsWMUzP/e85kgc5kDi4AoIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBzUiBJDbyy6MDdqzd+6d5XnOrPo3DJEgUXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GSmQxM5PyRuwYw3v5t+z8IZXDADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRAkmstWhMVOs6+854XnPd5M6ojoWhiysgAIAJAgQAMOEpQJWVlZo9e7ZSU1OVlZWlJUuWqLGxMWKfefPmyefzRWyrV6+O6dAAgMTnKUC1tbUqKytTfX293n//ffX29mrBggXq7u6O2G/lypVqbW0Nb+vXr4/p0ACAxOfpTQi7du2K+Hjz5s3KyspSQ0OD5s6dG358zJgxysnJic2EAICkdE3fA+rsvPiul4yMjIjH33zzTWVmZmr69OmqqKjQ6dOn+/0cPT09CoVCERsAIPlF/Tbsvr4+rV27VnfddZemT58efvyRRx7RxIkTFQwGdfDgQT377LNqbGzUO++8c9nPU1lZqZdeeinaMQAACSrqAJWVlenQoUP66KOPIh5ftWpV+M8zZsxQbm6u5s+fr+bmZk2ePPmSz1NRUaHy8vLwx6FQSHl5edGOBQBIEFEFaM2aNXrvvfe0Z88ejR8//or7FhYWSpKampouGyC/3y+/3x/NGACABOYpQM45Pfnkk9q+fbtqamqUn59/1TUHDhyQJOXm5kY1IAAgOXkKUFlZmbZs2aKdO3cqNTVVbW1tkqRAIKDRo0erublZW7Zs0f3336+xY8fq4MGDeuqppzR37lzNnDkzLn8BAEBi8hSgDRs2SLr4w6Z/b9OmTVqxYoVSUlK0e/duvfrqq+ru7lZeXp6WLl2q5557LmYDAwCSg+cvwV1JXl6eamtrr2kgAMDQwN2wgSSW9x/tUa1bUrLM85q+T26I6lgYurgZKQDABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRAknswh+bo1qX8j3va4L6c1THwtDFFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATg+5ecM45SdJ59UrOeBgAgGfn1Svpb/8/78+gC1BXV5ck6SP93ngSAMC16OrqUiAQ6Pd5n7taogZYX1+fjh8/rtTUVPl8vojnQqGQ8vLydPToUaWlpRlNaI/zcBHn4SLOw0Wch4sGw3lwzqmrq0vBYFDDhvX/nZ5BdwU0bNgwjR8//or7pKWlDekX2Nc4DxdxHi7iPFzEebjI+jxc6crna7wJAQBgggABAEwkVID8fr/WrVsnv99vPYopzsNFnIeLOA8XcR4uSqTzMOjehAAAGBoS6goIAJA8CBAAwAQBAgCYIEAAABMJE6CqqirddNNNGjVqlAoLC/Xpp59ajzTgXnzxRfl8voht6tSp1mPF3Z49e7Ro0SIFg0H5fD7t2LEj4nnnnF544QXl5uZq9OjRKi4u1uHDh22GjaOrnYcVK1Zc8vpYuHChzbBxUllZqdmzZys1NVVZWVlasmSJGhsbI/Y5e/asysrKNHbsWF1//fVaunSp2tvbjSaOj3/kPMybN++S18Pq1auNJr68hAjQ22+/rfLycq1bt06fffaZCgoKVFJSohMnTliPNuCmTZum1tbW8PbRRx9ZjxR33d3dKigoUFVV1WWfX79+vV577TVt3LhRe/fu1XXXXaeSkhKdPXt2gCeNr6udB0lauHBhxOtj69atAzhh/NXW1qqsrEz19fV6//331dvbqwULFqi7uzu8z1NPPaV3331X27ZtU21trY4fP64HH3zQcOrY+0fOgyStXLky4vWwfv16o4n74RLAnDlzXFlZWfjjCxcuuGAw6CorKw2nGnjr1q1zBQUF1mOYkuS2b98e/rivr8/l5OS4l19+OfxYR0eH8/v9buvWrQYTDoxvngfnnFu+fLlbvHixyTxWTpw44SS52tpa59zF//YjR45027ZtC+/zxRdfOEmurq7Oasy4++Z5cM657373u+4HP/iB3VD/gEF/BXTu3Dk1NDSouLg4/NiwYcNUXFysuro6w8lsHD58WMFgUJMmTdKjjz6qI0eOWI9kqqWlRW1tbRGvj0AgoMLCwiH5+qipqVFWVpamTJmiJ554QidPnrQeKa46OzslSRkZGZKkhoYG9fb2Rrwepk6dqgkTJiT16+Gb5+Frb775pjIzMzV9+nRVVFTo9OnTFuP1a9DdjPSbvvrqK124cEHZ2dkRj2dnZ+vLL780mspGYWGhNm/erClTpqi1tVUvvfSS7rnnHh06dEipqanW45loa2uTpMu+Pr5+bqhYuHChHnzwQeXn56u5uVk//vGPVVpaqrq6Og0fPtx6vJjr6+vT2rVrddddd2n69OmSLr4eUlJSlJ6eHrFvMr8eLnceJOmRRx7RxIkTFQwGdfDgQT377LNqbGzUO++8YzhtpEEfIPxNaWlp+M8zZ85UYWGhJk6cqN/97nd6/PHHDSfDYLBs2bLwn2fMmKGZM2dq8uTJqqmp0fz58w0ni4+ysjIdOnRoSHwf9Er6Ow+rVq0K/3nGjBnKzc3V/Pnz1dzcrMmTJw/0mJc16L8El5mZqeHDh1/yLpb29nbl5OQYTTU4pKen69Zbb1VTU5P1KGa+fg3w+rjUpEmTlJmZmZSvjzVr1ui9997Thx9+GPHrW3JycnTu3Dl1dHRE7J+sr4f+zsPlFBYWStKgej0M+gClpKRo1qxZqq6uDj/W19en6upqFRUVGU5m79SpU2publZubq71KGby8/OVk5MT8foIhULau3fvkH99HDt2TCdPnkyq14dzTmvWrNH27dv1wQcfKD8/P+L5WbNmaeTIkRGvh8bGRh05ciSpXg9XOw+Xc+DAAUkaXK8H63dB/CPeeust5/f73ebNm93nn3/uVq1a5dLT011bW5v1aAPqhz/8oaupqXEtLS3u448/dsXFxS4zM9OdOHHCerS46urqcvv373f79+93ktwrr7zi9u/f7/785z8755z7+c9/7tLT093OnTvdwYMH3eLFi11+fr47c+aM8eSxdaXz0NXV5Z5++mlXV1fnWlpa3O7du923vvUtd8stt7izZ89ajx4zTzzxhAsEAq6mpsa1traGt9OnT4f3Wb16tZswYYL74IMP3L59+1xRUZErKioynDr2rnYempqa3E9+8hO3b98+19LS4nbu3OkmTZrk5s6dazx5pIQIkHPOvf76627ChAkuJSXFzZkzx9XX11uPNOAeeughl5ub61JSUtyNN97oHnroIdfU1GQ9Vtx9+OGHTtIl2/Lly51zF9+K/fzzz7vs7Gzn9/vd/PnzXWNjo+3QcXCl83D69Gm3YMECN27cODdy5Eg3ceJEt3LlyqT7R9rl/v6S3KZNm8L7nDlzxn3/+993N9xwgxszZox74IEHXGtrq93QcXC183DkyBE3d+5cl5GR4fx+v7v55pvdj370I9fZ2Wk7+Dfw6xgAACYG/feAAADJiQABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAw8Z+6VYAT0aIl0gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data_config.show(imgs[7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f31b2c-a862-4edc-bbf8-b5e6c05d75d1",
   "metadata": {},
   "source": [
    "# Example target pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ab521f5-a502-43cd-bd58-d49eb0c8285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "# All non-visible layers are encoded in a relationship\n",
    "class HiddenRelationship(Synapse):\n",
    "    \"\"\"Combine my labels and pixels in the case of MNIST\"\"\"\n",
    "    W1: jnp.ndarray = tx.Parameter.node()\n",
    "    W2: jnp.ndarray = tx.Parameter.node()\n",
    "    \n",
    "    def __init__(self, nhid:int, stdinit:float = 0.02):\n",
    "        self.nhid = nhid\n",
    "        self.stdinit = 0.02\n",
    "\n",
    "    def energy(self, g1, g2):\n",
    "        if self.initializing():\n",
    "            key = tx.next_key() \n",
    "            self.W1 = nn.initializers.normal(self.stdinit)(key, (g1.shape[0], self.nhid))\n",
    "            self.W2 = nn.initializers.normal(self.stdinit)(key, (g2.shape[0], self.nhid))\n",
    "        return LRelu(g1 @ self.W1 + g2 @ self.W2)\n",
    "        \n",
    "\n",
    "init_key = jax.random.PRNGKey(0)\n",
    "\n",
    "layers = [\n",
    "    IdentityLayer((784,)),\n",
    "    IdentityLayer((10,)),\n",
    "]\n",
    "synapses = [\n",
    "    HiddenRelationship(200),\n",
    "]\n",
    "\n",
    "connections = [\n",
    "    ((0,1), 0),\n",
    "]\n",
    "\n",
    "bs = 5\n",
    "states, ham = HAM(layers, synapses, connections).init_states_and_params(jax.random.PRNGKey(0), bs=bs)\n",
    "\n",
    "@jax.jit\n",
    "def forward_classification_mnist(model, x):\n",
    "    depth = 1\n",
    "    alpha = 0.1\n",
    "    \n",
    "    bs = x.shape[0]\n",
    "    xs = model.init_states(bs)\n",
    "    xs[0] = jnp.array(x)\n",
    "    for i in range(depth):\n",
    "        updates = model.vgrad(xs)\n",
    "        xs = jtu.tree_map(lambda x, u: x - alpha * u, xs, updates)\n",
    "    \n",
    "    logits = xs[1]\n",
    "    return logits\n",
    "\n",
    "batch = {\n",
    "    \"images\": jnp.array(b[0][:10]),\n",
    "    \"labels\": jnp.array(b[1][:10])\n",
    "}\n",
    "x = rearrange(batch[\"images\"], \"bs ... -> bs (...)\")\n",
    "\n",
    "logits = forward_classification_mnist(ham, x)\n",
    "print(logits.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c89f1b-cd6a-499a-ac86-be0fe07b6e91",
   "metadata": {},
   "source": [
    "# Training Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cef6e47b-b229-464e-9cff-471f8f6af39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(tx.Module):\n",
    "    model: tx.Module\n",
    "    optimizer: tx.Optimizer\n",
    "    apply_fn: Callable\n",
    "    \n",
    "    def __init__(self, model, optimizer, apply_fn):\n",
    "        self.model = model\n",
    "        self.optimizer = tx.Optimizer(optimizer).init(self.params)\n",
    "        self.apply_fn = apply_fn\n",
    "        \n",
    "    @property\n",
    "    def params(self):\n",
    "        return self.model.filter(tx.Parameter)\n",
    "    \n",
    "    def apply_updates(self, grads):\n",
    "        new_params = self.optimizer.update(grads, self.params)\n",
    "        self.model = self.model.merge(new_params)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a7984df-7ecc-470c-a93e-760d0a9ccab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(*, logits, labels):\n",
    "    n_classes = logits.shape[-1]\n",
    "    labels_onehot = jax.nn.one_hot(labels, num_classes=n_classes)\n",
    "    return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()\n",
    "\n",
    "def compute_metrics(*, logits, labels):\n",
    "    loss = cross_entropy_loss(logits=logits, labels=labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    metrics = {\n",
    "      'loss': loss,\n",
    "      'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9da397d3-f6af-4a1d-b084-d3a6482409be",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        state.model = state.model.merge(params)\n",
    "        x = rearrange(batch[\"image\"], \"bs ... -> bs (...)\")\n",
    "        logits = state.apply_fn(state.model, x)\n",
    "        loss = cross_entropy_loss(logits=logits, labels=batch[\"label\"])\n",
    "        return loss, (logits, state)\n",
    "        \n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, (logits, state)), grads = grad_fn(state.params)\n",
    "    \n",
    "    state = state.apply_updates(grads)\n",
    "    metrics = compute_metrics(logits=logits, labels=batch['label'])\n",
    "    return state, metrics\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(state, batch):\n",
    "    x = rearrange(batch[\"image\"], \"bs ... -> bs (...)\")\n",
    "    logits = state.apply_fn(state.model, x)\n",
    "    logit_pred = jnp.argmax(logits, axis=-1)\n",
    "    return compute_metrics(logits=logits, labels=batch['label'])\n",
    "\n",
    "def train_epoch(state, train_dl, epoch):\n",
    "    \"\"\"Train for a single epoch.\"\"\"\n",
    "    batch_metrics = []\n",
    "    bs = train_dl.batch_size\n",
    "    for i, batch in enumerate(train_dl):\n",
    "        if (i % 100) == 0:\n",
    "            print(\"Starting example: \", i*bs)\n",
    "        batch = {\n",
    "            \"image\": jnp.array(batch[0]),\n",
    "            \"label\": jnp.array(batch[1])\n",
    "        }\n",
    "        state, metrics = train_step(state, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "            \n",
    "\n",
    "    # compute mean of metrics across each batch in epoch.\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    epoch_metrics_np = {\n",
    "      k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "      for k in batch_metrics_np[0]}\n",
    "\n",
    "    print('train epoch: %d, loss: %.4f, accuracy: %.2f' % (\n",
    "      epoch, epoch_metrics_np['loss'], epoch_metrics_np['accuracy'] * 100))\n",
    "\n",
    "    return state, epoch_metrics_np['loss'], epoch_metrics_np['accuracy'] * 100\n",
    "\n",
    "def eval_model(params, test_dl):\n",
    "    batch_metrics = []\n",
    "    bs = test_dl.batch_size\n",
    "\n",
    "    for i, batch in enumerate(test_dl):\n",
    "        if (i % 1000) == 0:\n",
    "                print(\"Starting example: \", i*bs)\n",
    "        batch = {\n",
    "            \"image\": jnp.array(batch[0]),\n",
    "            \"label\": jnp.array(batch[1])\n",
    "        }\n",
    "        \n",
    "        metrics = eval_step(params, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    summary = {\n",
    "      k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "      for k in batch_metrics_np[0]\n",
    "    }\n",
    "\n",
    "    return summary['loss'], summary['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9e77e-f9bc-4606-933b-318453f431fe",
   "metadata": {},
   "source": [
    "## Convolutional MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d4d3e9-a82a-411c-9851-b6ae42bc72a0",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd49ec10-2a0e-4e7b-8194-9737284af8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        state.model = state.model.merge(params)\n",
    "        x = batch[\"image\"]\n",
    "        logits = state.apply_fn(state.model, x)\n",
    "        loss = cross_entropy_loss(logits=logits, labels=batch[\"label\"])\n",
    "        return loss, (logits, state)\n",
    "        \n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, (logits, state)), grads = grad_fn(state.params)\n",
    "    \n",
    "    state = state.apply_updates(grads)\n",
    "    metrics = compute_metrics(logits=logits, labels=batch['label'])\n",
    "    return state, metrics\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(state, batch):\n",
    "    x = batch[\"image\"]\n",
    "    logits = state.apply_fn(state.model, x)\n",
    "    logit_pred = jnp.argmax(logits, axis=-1)\n",
    "    return compute_metrics(logits=logits, labels=batch['label'])\n",
    "\n",
    "# # Example loading CIFAR. We need an \"args\" and a \"data_config\"\n",
    "# args = DataloadingArgs(\n",
    "#     dataset=\"torch/CIFAR10\",\n",
    "#     # aa=\"rand\",\n",
    "#     aa=None,\n",
    "#     reprob=0.2,\n",
    "#     vflip=0.2,\n",
    "#     hflip=0.5,\n",
    "#     batch_size=128,\n",
    "#     validation_batch_size=10_000, # Get the entire validation set at once\n",
    "# )\n",
    "# data_config = DataConfigCIFAR10()\n",
    "\n",
    "# ## Example loading ImageNet. We need an \"args\" and a \"data_config\"\n",
    "# args = DataloadingArgs(\n",
    "#     data_dir=Path.home()/\"datasets/timm-datasets/ImageNet100\",\n",
    "#     aa=None,\n",
    "#     reprob=0.1,\n",
    "#     vflip=0.0,\n",
    "#     hflip=0.5,\n",
    "#     batch_size=256,\n",
    "#     validation_batch_size=500\n",
    "# )\n",
    "# data_config = DataConfigImageNet(input_size=(3,128,128)) # Feel free to change the input size of our dataset!\n",
    "\n",
    "## Example loading MNIST\n",
    "args = DataloadingArgs(\n",
    "    dataset=\"torch/MNIST\",\n",
    "    aa=None,\n",
    "    reprob=0.0,\n",
    "    vflip=0.,\n",
    "    hflip=0.,\n",
    "    scale=(0.8,1.),\n",
    "    batch_size=2000,\n",
    "    color_jitter=0.,\n",
    "    validation_batch_size=10_000,\n",
    ")\n",
    "data_config = DataConfigMNIST(input_size=(1,28,28))\n",
    "\n",
    "train_dl, eval_dl = create_dataloaders(args, data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ab29940-8979-4c47-b915-4197f5874981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All non-visible layers are encoded in a relationship\n",
    "class HiddenRelationship(Synapse):\n",
    "    \"\"\"Combine my labels and pixels in the case of MNIST\"\"\"\n",
    "    W1: jnp.ndarray = tx.Parameter.node()\n",
    "    W2: jnp.ndarray = tx.Parameter.node()\n",
    "    \n",
    "    def __init__(self, nhid:int, stdinit:float = 0.02):\n",
    "        self.nhid = nhid\n",
    "        self.stdinit = 0.02\n",
    "\n",
    "    def energy(self, g1, g2):\n",
    "        if self.initializing():\n",
    "            key = tx.next_key() \n",
    "            self.W1 = nn.initializers.normal(self.stdinit)(key, (g1.shape[0], self.nhid))\n",
    "            self.W2 = nn.initializers.normal(self.stdinit)(key, (g2.shape[0], self.nhid))\n",
    "        return LRelu(g1 @ self.W1 + g2 @ self.W2)\n",
    "\n",
    "\n",
    "class ConvSynapse(Synapse):\n",
    "    conv: tx.Module    \n",
    "    \n",
    "    def __init__(self, conv:tx.Module):\n",
    "        self.conv = conv\n",
    "\n",
    "    def energy(self, g1, g2):\n",
    "        if self.initializing():\n",
    "            key = tx.next_key()\n",
    "            features_in = g1.shape[0]\n",
    "            features_out = g2.shape[0]\n",
    "            self.conv = self.conv.init(key, g1)\n",
    "        return jnp.multiply(g2, self.conv(g1)).sum()\n",
    "        \n",
    "init_key = jax.random.PRNGKey(0)\n",
    "\n",
    "# layers = [\n",
    "#     IdentityLayer((1,28,28)),\n",
    "#     ReluLayer(),\n",
    "#     IdentityLayer((10,)),\n",
    "# ]\n",
    "# synapses = [\n",
    "#     HiddenRelationship(200),\n",
    "# ]\n",
    "\n",
    "# connections = [\n",
    "#     ((0,1), 0),\n",
    "# ]\n",
    "\n",
    "\n",
    "# @jax.jit\n",
    "# def forward_classification_mnist(model, x):\n",
    "#     depth = 4\n",
    "#     alpha = 1.\n",
    "    \n",
    "#     bs = x.shape[0]\n",
    "#     xs = model.init_states(bs)\n",
    "#     masks = jtu.tree_map(lambda x: jnp.ones_like(x, dtype=jnp.int8), xs)\n",
    "#     xs[0] = jnp.array(x)\n",
    "#     masks[0] = jnp.zeros_like(masks[0], dtype=jnp.int8)\n",
    "\n",
    "#     for i in range(depth):\n",
    "#         updates = model.vgrad(xs)\n",
    "#         xs = jtu.tree_map(lambda x, u, m: x - alpha * u * m, xs, updates, masks)\n",
    "    \n",
    "#     logits = xs[1]\n",
    "#     return logits\n",
    "\n",
    "\n",
    "# bs = 1\n",
    "# states, ham = HAM(layers, synapses, connections).init_states_and_params(jax.random.PRNGKey(0), bs=bs)\n",
    "\n",
    "# optimizer = optax.adamw(0.001)\n",
    "# state = TrainState(ham, optimizer, forward_classification_mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9225fc5e-02f9-4281-9609-d509681a542b",
   "metadata": {},
   "source": [
    "### Training Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df4a0b55-d0c7-40a6-8395-e49d1c9d580b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# num_epochs = 100\n",
    "# train_acc_list=[]\n",
    "# test_acc_list=[]\n",
    "\n",
    "# for epoch in range(1, num_epochs + 1):\n",
    "#     # Use a separate PRNG key to permute image data during shuffling\n",
    "#     state, train_loss, train_acc = train_epoch(state, train_dl, epoch)\n",
    "\n",
    "#     # Evaluate on the test set after each training epoch \n",
    "#     test_loss, test_acc = eval_model(state, eval_dl)\n",
    "#     train_acc_list.append(train_acc)\n",
    "#     test_acc_list.append(100*test_acc)\n",
    "#     print(f\"Max acc test: {np.max(test_acc_list)}\")\n",
    "#     print(f\"Acc epoch {epoch} [train/tst]: [{train_acc}/{test_acc}]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd285c3-0a83-4867-9341-822faa559d4e",
   "metadata": {},
   "source": [
    "## Vectorized MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c931ca-35d0-4b77-b7e4-bc1a46f37f2f",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9b38124-80fa-401a-97af-8b6759e481aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Example loading CIFAR. We need an \"args\" and a \"data_config\"\n",
    "# args = DataloadingArgs(\n",
    "#     dataset=\"torch/CIFAR10\",\n",
    "#     # aa=\"rand\",\n",
    "#     aa=None,\n",
    "#     reprob=0.2,\n",
    "#     vflip=0.2,\n",
    "#     hflip=0.5,\n",
    "#     batch_size=128,\n",
    "#     validation_batch_size=10_000, # Get the entire validation set at once\n",
    "# )\n",
    "# data_config = DataConfigCIFAR10()\n",
    "\n",
    "# ## Example loading ImageNet. We need an \"args\" and a \"data_config\"\n",
    "# args = DataloadingArgs(\n",
    "#     data_dir=Path.home()/\"datasets/timm-datasets/ImageNet100\",\n",
    "#     aa=None,\n",
    "#     reprob=0.1,\n",
    "#     vflip=0.0,\n",
    "#     hflip=0.5,\n",
    "#     batch_size=256,\n",
    "#     validation_batch_size=500\n",
    "# )\n",
    "# data_config = DataConfigImageNet(input_size=(3,128,128)) # Feel free to change the input size of our dataset!\n",
    "\n",
    "## Example loading MNIST\n",
    "args = DataloadingArgs(\n",
    "    dataset=\"torch/MNIST\",\n",
    "    aa=None,\n",
    "    reprob=0.1,\n",
    "    vflip=0.,\n",
    "    hflip=0.,\n",
    "    scale=(0.7,1.),\n",
    "    batch_size=100,\n",
    "    # batch_size=2000,\n",
    "    color_jitter=0.4,\n",
    "    validation_batch_size=1000,\n",
    ")\n",
    "data_config = DataConfigMNIST(input_size=(1,28,28))\n",
    "\n",
    "train_dl, eval_dl = create_dataloaders(args, data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "805cec70-b576-44c8-ac98-dd4a978e4b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All non-visible layers are encoded in a relationship\n",
    "class HiddenRelationship(Synapse):\n",
    "    \"\"\"Combine my labels and pixels in the case of MNIST\"\"\"\n",
    "    W1: jnp.ndarray = tx.Parameter.node()\n",
    "    W2: jnp.ndarray = tx.Parameter.node()\n",
    "    beta: jnp.ndarray = tx.Parameter.node()\n",
    "    \n",
    "    def __init__(self, nhid:int, stdinit:float = 0.02, beta_init=1.):\n",
    "        self.nhid = nhid\n",
    "        self.stdinit = 0.02\n",
    "        self.beta = jnp.array(beta_init)\n",
    "\n",
    "    def energy(self, g1, g2):\n",
    "        if self.initializing():\n",
    "            key = tx.next_key() \n",
    "            self.W1 = nn.initializers.normal(self.stdinit)(key, (g1.shape[0], self.nhid))\n",
    "            self.W2 = nn.initializers.normal(self.stdinit)(key, (g2.shape[0], self.nhid))\n",
    "        # return LSoftmax(g1 @ self.W1 + g2 @ self.W2, self.beta.clip(1e-6))\n",
    "        return LRelu(g1 @ self.W1 + g2 @ self.W2)\n",
    "\n",
    "    \n",
    "## This wasn't particularly useful\n",
    "# class Hidden2LayerRelationship(Synapse):\n",
    "#     \"\"\"Combine my labels and pixels in the case of MNIST\"\"\"\n",
    "#     W1: jnp.ndarray = tx.Parameter.node()\n",
    "#     W2: jnp.ndarray = tx.Parameter.node()\n",
    "#     W3: jnp.ndarray = tx.Parameter.node()\n",
    "    \n",
    "#     def __init__(self, nhid:int, stdinit:float = 0.02):\n",
    "#         self.nhid = nhid\n",
    "#         self.stdinit = 0.02\n",
    "\n",
    "#     def energy(self, g1, g2):\n",
    "#         if self.initializing():\n",
    "#             key = tx.next_key() \n",
    "#             self.W1 = nn.initializers.normal(self.stdinit)(key, (g1.shape[0], self.nhid))\n",
    "#             self.W2 = nn.initializers.normal(self.stdinit)(key, (g2.shape[0], self.nhid))\n",
    "#             self.W3 = nn.initializers.normal(self.stdinit)(key, (self.nhid, self.nhid))\n",
    "#         x = g1 @ self.W1 + g2 @ self.W2\n",
    "#         return LRelu(x)\n",
    "#         # x = jax.nn.tanh(g1 @ self.W1 + g2 @ self.W2)\n",
    "#         # return LRelu(x @ self.W3)\n",
    "        \n",
    "        \n",
    "init_key = jax.random.PRNGKey(0)\n",
    "\n",
    "layers = [\n",
    "    IdentityLayer((784,)),\n",
    "    IdentityLayer((10,)),\n",
    "]\n",
    "synapses = [\n",
    "    HiddenRelationship(30),\n",
    "]\n",
    "\n",
    "connections = [\n",
    "    ((0,1), 0),\n",
    "]\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def forward_classification_mnist(model, x):\n",
    "    depth = 4\n",
    "    alpha = 1.\n",
    "    \n",
    "    bs = x.shape[0]\n",
    "    x = rearrange(x, \"... h w -> ... (h w)\")\n",
    "    xs = model.init_states(bs)\n",
    "    masks = jtu.tree_map(lambda x: jnp.ones_like(x, dtype=jnp.int8), xs)\n",
    "    xs[0] = jnp.array(x)\n",
    "    masks[0] = jnp.zeros_like(masks[0], dtype=jnp.int8)\n",
    "\n",
    "    for i in range(depth):\n",
    "        updates = model.vgrad(xs)\n",
    "        xs = jtu.tree_map(lambda x, u, m: x - alpha * u * m, xs, updates, masks)\n",
    "    \n",
    "    logits = xs[1]\n",
    "    return logits\n",
    "\n",
    "\n",
    "bs = 1\n",
    "states, ham = HAM(layers, synapses, connections).init_states_and_params(jax.random.PRNGKey(0), bs=bs)\n",
    "\n",
    "optimizer = optax.adamw(0.001)\n",
    "state = TrainState(ham, optimizer, forward_classification_mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a844f8e-ab30-4088-9f30-f7d905d25835",
   "metadata": {},
   "source": [
    "### Training Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec3e4882-eb26-46f9-83e3-cf481b9b1637",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 2397599, 2397635, 2397671, 2397707) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/energy-ham/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m~/miniconda3/envs/energy-ham/lib/python3.9/multiprocessing/queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m test_acc_list\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Use a separate PRNG key to permute image data during shuffling\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     state, train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Evaluate on the test set after each training epoch \u001b[39;00m\n\u001b[1;32m     10\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m eval_model(state, eval_dl)\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(state, train_dl, epoch)\u001b[0m\n\u001b[1;32m     26\u001b[0m batch_metrics \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m bs \u001b[38;5;241m=\u001b[39m train_dl\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting example: \u001b[39m\u001b[38;5;124m\"\u001b[39m, i\u001b[38;5;241m*\u001b[39mbs)\n",
      "File \u001b[0;32m~/miniconda3/envs/energy-ham/lib/python3.9/site-packages/torch/utils/data/dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator()\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/energy-ham/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1142\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._reset\u001b[0;34m(self, loader, first_iter)\u001b[0m\n\u001b[1;32m   1140\u001b[0m resume_iteration_cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m resume_iteration_cnt \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1142\u001b[0m     return_idx, return_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_idx, _utils\u001b[38;5;241m.\u001b[39mworker\u001b[38;5;241m.\u001b[39m_ResumeIteration):\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m return_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/energy-ham/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1327\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/energy-ham/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1176\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1175\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pids_str)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 2397599, 2397635, 2397671, 2397707) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "train_acc_list=[]\n",
    "test_acc_list=[]\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Use a separate PRNG key to permute image data during shuffling\n",
    "    state, train_loss, train_acc = train_epoch(state, train_dl, epoch)\n",
    "\n",
    "    # Evaluate on the test set after each training epoch \n",
    "    test_loss, test_acc = eval_model(state, eval_dl)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_acc_list.append(100*test_acc)\n",
    "    print(f\"Max acc test: {np.max(test_acc_list)}\")\n",
    "    print(f\"Acc epoch {epoch} [train/tst]: [{train_acc}/{test_acc}]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a45ace6-dc78-47a5-94b2-fc5279ce5746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytree_save(ham.to_dict(), \"./mnist_model\")\n",
    "# outmodel = pytree_load(\"./mnist_model.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db9351-cadb-449f-8a31-a6d2b3faabe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytree_save(ham, \"./mnist_model_ham\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edfe63c-a6c7-409b-af13-d4037bfca78b",
   "metadata": {},
   "source": [
    "## Quick interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761a86d5-3584-4afc-98e3-be03d4f8df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_interpretability(model:tx.Module, logit_state:jnp.ndarray):\n",
    "    depth = 12\n",
    "    alpha = 1.\n",
    "    \n",
    "    \n",
    "    xs = model.init_states()\n",
    "    xs_list = np.empty((depth, xs[0].shape[0]))\n",
    "\n",
    "    assert logit_state.shape == xs[1].shape\n",
    "    xs[1] = logit_state\n",
    "    masks = jtu.tree_map(lambda x: jnp.ones_like(x, dtype=jnp.int8), xs)\n",
    "    masks[1] = jnp.zeros_like(masks[1], dtype=jnp.int8)\n",
    "    \n",
    "    mgrad = jax.jit(model.grad)\n",
    "    \n",
    "    @jax.jit\n",
    "    def step(model, xs):\n",
    "        updates = model.grad(xs)\n",
    "        xs = jtu.tree_map(lambda x, u, m: x - alpha * u * m, xs, updates, masks)\n",
    "        return xs\n",
    "\n",
    "    for i in range(depth):\n",
    "        xs = step(model, xs)\n",
    "        xs_list[i] = xs[0]\n",
    "    \n",
    "    # Return the pixels, vectorized\n",
    "    return xs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b3a1c-7d3a-44cf-a52e-5bad9c94338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frz_logits = jnp.zeros(10, dtype=jnp.float32).at[0].set(50)\n",
    "xs_list = forward_interpretability(ham, frz_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1cf04a-e422-406b-a8f4-d4611e3592ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba40cf6-0e35-4986-8ab6-4925a125ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_mnist_imgs(x):\n",
    "    return rearrange(x, \"... (h w) -> ... h w\", h=28, w=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2bdd53-0246-4071-8a06-e59ffd680ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = restore_mnist_imgs(xs_list) + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e10173-a1f3-42e8-84e5-333766abd68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trajectory[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb806b4-d088-48c4-a084-c05b2fe2e2e0",
   "metadata": {},
   "source": [
    "So that trajectory isn't displaying what I want it to. What is the issue?\n",
    "\n",
    "Visualize the weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7a03dd-2ae3-4dca-84e3-2388dba66869",
   "metadata": {},
   "outputs": [],
   "source": [
    "immems = ham.synapses[0].W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b217db-957f-47e8-84da-e5b747771239",
   "metadata": {},
   "outputs": [],
   "source": [
    "mems = restore_mnist_imgs(immems.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a88e7b-293b-4000-87ee-8b2cdaee2605",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mems[40])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hamux]",
   "language": "python",
   "name": "conda-env-hamux-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
