{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "464acfcb-4214-4646-8ae8-348d3a596e6c",
   "metadata": {},
   "source": [
    "# Registry\n",
    "\n",
    "> Easily create preconfigured models and prediction functions on a HAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe26cac9-25d4-4044-89f5-aa6d0ccbf78f",
   "metadata": {},
   "source": [
    "We create very simple helper functions to instantiate HAMs with particular architectural choices. Inspired by [`timm`](https://github.com/rwightman/pytorch-image-models).\n",
    "\n",
    "A HAM is a fundamentally general purpose architecture. It is a general-purpose Associative Memory -- it is up to the user to extract the desired information from the system. Hence, every registered model must return the `ham` architecture and a `fwd` function that accomplishes a task from that architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0e3694-f799-4aa4-83b7-4a323817d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79400474-fe9a-42cc-ae5e-78feb69831f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "import hamux as hmx\n",
    "from typing import *\n",
    "import functools as ft\n",
    "from fastcore.utils import *\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import treex as tx\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8503e8-3a96-4cd3-802e-83d288a6f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2055d-603e-491f-a5b8-15857644b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "warnings.simplefilter('ignore')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f6083e-0216-4efd-8678-18f2e8d19288",
   "metadata": {},
   "source": [
    "## The Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ae429-afbd-457c-b2be-fb15b9bdbc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "__MODELS = {}\n",
    "\n",
    "def register_model(fgen:Callable): # Function that returns a HAM with desired config\n",
    "    \"\"\"Register a function that returns a model configuration factory function.\n",
    "    The name of the function acts as the retrieval key and must be unique across models\"\"\"\n",
    "    __MODELS[fgen.__name__] = fgen\n",
    "    return fgen\n",
    "\n",
    "def create_model(mname:str, # Retrieve this stored model name\n",
    "                 *args, # Passed to retrieved factory function\n",
    "                 **kwargs): # Passed to retrieved factory function\n",
    "    \"\"\"Retrieve the model name from all registered models, passing `args` and `kwargs` to the factory function\"\"\"\n",
    "    assert mname in __MODELS, f\"Model '{mname}' has not been registered\"\n",
    "    return __MODELS[mname](*args, **kwargs)\n",
    "\n",
    "def named_partial(f, *args, new_name=None, order=None, **kwargs):\n",
    "    \"\"\"Like `functools.partial` but also copies over function name and docstring. \n",
    "    \n",
    "    If new_name is not None, use that as the name\n",
    "    \"\"\"\n",
    "    fnew = ft.partial(f,*args,**kwargs)\n",
    "    fnew.__doc__ = f.__doc__\n",
    "    name = new_name if new_name is not None else f.__name__\n",
    "    fnew.__name__ = name\n",
    "    if order is not None: fnew.order=order\n",
    "    elif hasattr(f,'order'): fnew.order=f.order\n",
    "    return fnew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca35daca-7730-48f9-8102-8ca6248c1933",
   "metadata": {},
   "source": [
    "We can now register a model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3636da5-2214-43ad-a812-6dae39a26c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_model\n",
    "def example_classical_hn(img_shape:Tuple, # Vector input size\n",
    "            label_shape:Tuple[int], # Number of labels\n",
    "            nhid:int=1000, # Number of hidden units in the single hidden layer\n",
    "            depth:int=4, # Default number of iterations to run the Hopfield Network prediction function\n",
    "            dt:float=0.4, # Default step size of the system\n",
    "           ): \n",
    "    \"\"\"Create a 2-layer classical Hopfield Network applied on vectorized inputs and a function showing how to use it\"\"\"\n",
    "    layers = [\n",
    "        hmx.TanhLayer(img_shape),\n",
    "        hmx.SoftmaxLayer(label_shape),\n",
    "    ]\n",
    "\n",
    "    synapses = [\n",
    "        hmx.DenseMatrixSynapseWithHiddenLayer(nhid, hidden_lagrangian=hmx.lagrangians.LRelu()),\n",
    "    ]\n",
    "\n",
    "    connections = [\n",
    "        ((0, 1), 0),\n",
    "    ]\n",
    "\n",
    "    ham = hmx.HAM(layers, synapses, connections)\n",
    "    \n",
    "    def fwd(model, x, depth=depth, dt=dt, rng=None):\n",
    "        \"\"\"A pure function to extract desired information from the configured HAM, applied on batched inputs\"\"\"\n",
    "        # Initialize hidden states to our image\n",
    "        xs = model.init_states(x.shape[0], rng=rng)\n",
    "        xs[0] = jnp.array(x)\n",
    "\n",
    "        # Masks allow us to clamp our visible data over time\n",
    "        masks = jtu.tree_map(lambda x: jnp.ones_like(x, dtype=jnp.int8), xs)\n",
    "        masks[0] = jnp.zeros_like(masks[0], dtype=jnp.int8)  # Don't evolve images\n",
    "\n",
    "        for i in range(depth):\n",
    "            updates = model.vupdates(xs)  # Calculate the updates\n",
    "            xs = model.step(\n",
    "                xs, updates, dt=dt, masks=masks\n",
    "            )  # Add them to our current states\n",
    "\n",
    "        # All labels have a softmax activation function as the last layer, spitting out probabilities\n",
    "        return model.layers[-1].g(xs[-1])\n",
    "\n",
    "    return ham, fwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de20bc-af4b-48ca-9194-adee01cd31e7",
   "metadata": {},
   "source": [
    "The model that we just created comes with a default function that predicts label probabilities after 4 steps (though feel free to write any function to extract a layer state/activation at any point in time).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213e631-459b-45e7-9044-14ca3d5bb41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 16:24:58.481170: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 10)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_shape = (32,32); bs = 12\n",
    "model, fwd = create_model(\"example_classical_hn\", img_shape=img_shape, label_shape=(10,))\n",
    "\n",
    "_, model = model.init_states_and_params(jax.random.PRNGKey(0))\n",
    "x = jnp.ones((bs, *img_shape))\n",
    "probs = fwd(model, x); probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03969322-7b45-4478-8bf2-ef41b67084c6",
   "metadata": {},
   "source": [
    "For the simple pipeline of classification, our `fwd` pipelines are quite similar. We therefore create some helper functions to use throughout the rest of our model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e7f88e-4dfa-4595-936c-408050c547ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def simple_fwd(model:hmx.HAM, # HAM where layer[0] is the image input and layer[-1] are the labels\n",
    "               x: jnp.ndarray, # Starting point for clamped layer[0]\n",
    "               depth: int, # Number of iterations for which to run the model\n",
    "               dt: float, # Step size through time\n",
    "               rng: Optional[jnp.ndarray]=None): # If provided, initialize states to random instead of 0\n",
    "    \"\"\"A simple version of the forward function for showing in the paper.\n",
    "\n",
    "    All time constants `tau` are set to be 1 in our architecture, but this is variable\n",
    "    \"\"\"\n",
    "    # Initialize hidden states to our image\n",
    "    xs = model.init_states(x.shape[0], rng=rng)\n",
    "    xs[0] = jnp.array(x)\n",
    "\n",
    "    # Masks allow us to clamp our visible data over time\n",
    "    masks = jtu.tree_map(lambda x: jnp.ones_like(x, dtype=jnp.int8), xs)\n",
    "    masks[0] = jnp.zeros_like(masks[0], dtype=jnp.int8)  # Don't evolve images\n",
    "\n",
    "    for i in range(depth):\n",
    "        updates = model.vupdates(xs)  # Calculate the updates\n",
    "        xs = model.step(\n",
    "            xs, updates, dt=dt, masks=masks\n",
    "        )  # Add them to our current states\n",
    "\n",
    "    # All labels have a softmax activation function as the last layer, spitting out probabilities\n",
    "    return model.layers[-1].g(xs[-1])\n",
    "\n",
    "def fwd_vec(model:hmx.HAM, # HAM where layer[0] is the image input and layer[-1] are the labels\n",
    "               x: jnp.ndarray, # Starting point for clamped layer[0]\n",
    "               depth: int, # Number of iterations for which to run the model\n",
    "               dt: float, # Step size through time\n",
    "               rng: Optional[jnp.ndarray]=None): # If provided, initialize states to random instead of 0\n",
    "    \"\"\"Where the image input is vectorized\"\"\"\n",
    "    x = rearrange(x, \"... c h w -> ... (c h w)\")\n",
    "    return simple_fwd(model, x, depth, dt, rng)\n",
    "\n",
    "def fwd_conv(model:hmx.HAM, # HAM where layer[0] is the image input and layer[-1] are the labels\n",
    "               x: jnp.ndarray, # Starting point for clamped layer[0]\n",
    "               depth: int, # Number of iterations for which to run the model\n",
    "               dt: float, # Step size through time\n",
    "               rng: Optional[jnp.ndarray]=None): # If provided, initialize states to random instead of 0\n",
    "    \"\"\"Where the image input is kept as a 3 channel image\"\"\"\n",
    "    x = rearrange(x, \"... c h w -> ... h w c\")\n",
    "    return simple_fwd(model,x, depth,dt, rng)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55236146-a0d3-432f-9c31-350b65828287",
   "metadata": {},
   "source": [
    "## Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d72ada-5b30-4a8d-9fab-5e17644c1f9e",
   "metadata": {},
   "source": [
    "### 2 Layer HN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d303d4-6eb6-4d73-bb4e-becc86741618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@register_model\n",
    "def hn(hidden_lagrangian:tx.Module,\n",
    "       img_shape: Tuple, # Shape of image input to model\n",
    "       label_shape: Tuple, # Shape of label probabilities,typically (NLABELS,)\n",
    "       nhid:int=1000, # Number of units in hidden layer\n",
    "       do_norm:bool=False): # If provided, enforce that all weights are standardized\n",
    "    \"\"\"Create a Classical Hopfield Network that is intended to be applied on vectorized inputs\"\"\"\n",
    "    layers = [\n",
    "        hmx.TanhLayer(img_shape),\n",
    "        hmx.SoftmaxLayer(label_shape),\n",
    "    ]\n",
    "\n",
    "    synapses = [\n",
    "        hmx.DenseMatrixSynapseWithHiddenLayer(nhid, hidden_lagrangian=hidden_lagrangian, do_norm=do_norm),\n",
    "    ]\n",
    "\n",
    "    connections = [\n",
    "        ((0, 1), 0),\n",
    "    ]\n",
    "\n",
    "    ham = hmx.HAM(layers, synapses, connections)\n",
    "\n",
    "    forward = ft.partial(fwd_vec, depth=4, dt=0.4)\n",
    "\n",
    "    return ham, forward\n",
    "\n",
    "hn_relu = named_partial(hn, hmx.lagrangians.LRelu(), new_name=\"hn_relu\")\n",
    "register_model(hn_relu)\n",
    "\n",
    "hn_repu5 = named_partial(hn, hmx.lagrangians.LRepu(n=5), new_name=\"hn_repu5\")\n",
    "register_model(hn_repu5)\n",
    "\n",
    "hn_softmax = named_partial(hn, hmx.lagrangians.LSoftmax(), new_name=\"hn_softmax\")\n",
    "register_model(hn_softmax)\n",
    "\n",
    "@register_model\n",
    "def hn_relu_mnist(nhid:int=1000): # Number of units in the single hidden layer\n",
    "    \"\"\"Vectorized HN on flattened MNIST\"\"\"\n",
    "    return hn_relu(img_shape=(784,), label_shape=(10,), nhid=nhid)\n",
    "\n",
    "@register_model\n",
    "def hn_relu_cifar(nhid:int=6000): # Number of units in the single hidden layer\n",
    "    \"\"\"Vectorized HN on flattened CIFAR10\"\"\"\n",
    "    return hn_relu(img_shape=(3072,), label_shape=(10,), nhid=nhid)\n",
    "\n",
    "@register_model\n",
    "def hn_repu5_mnist(nhid=1000):\n",
    "    \"\"\"Vectorized DAM on flattened MNIST\"\"\"\n",
    "    return hn_repu5(img_shape=(784,), label_shape=(10,), nhid=nhid)\n",
    "\n",
    "@register_model\n",
    "def hn_repu5_cifar(nhid=6000):\n",
    "    \"\"\"Vectorized DAM on flattened CIFAR\"\"\"\n",
    "    return hn_repu5(img_shape=(3072,), label_shape=(10,), nhid=nhid)\n",
    "\n",
    "@register_model\n",
    "def hn_softmax_mnist(nhid=1000):\n",
    "    return hn_softmax(img_shape=(784,), label_shape=(10,), nhid=nhid, do_norm=True)\n",
    "\n",
    "@register_model\n",
    "def hn_softmax_cifar(nhid=6000):\n",
    "    return hn_softmax(img_shape=(3072,), label_shape=(10,), nhid=nhid, do_norm=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1c8d86-1fe2-4f59-af06-0691eb74d1d3",
   "metadata": {},
   "source": [
    "These models can now be instantiated by their strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353421d-4b05-46b6-a783-4c879dc9cc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.31536135, 0.08483113, 0.0897951 , 0.02981309, 0.03241062,\n",
       "        0.03071734, 0.03666373, 0.00281298, 0.03433144, 0.3432633 ]],      dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xcifar = jnp.ones((1,3, 32,32)) # Per pytorch convention, CHW\n",
    "xmnist = jnp.ones((1,1,28,28)) # Per pytorch convention, CHW\n",
    "\n",
    "exhn, exhn_fwd = create_model(\"hn\", hmx.lagrangians.LExp(), (32,32,3), (10,))\n",
    "_, exhn = exhn.init_states_and_params(jax.random.PRNGKey(22))\n",
    "exhn_fwd(exhn, xcifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf646b1-3711-49e9-8f1d-f9fd8305ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# Additional tests for the registry\n",
    "\n",
    "# Relu model tests\n",
    "exhn_relu, exhn_relu_fwd = create_model(\"hn_relu\", (32,32,3), (10,))\n",
    "_, exhn_relu = exhn_relu.init_states_and_params(jax.random.PRNGKey(22))\n",
    "exhn_relu_fwd(exhn_relu, xcifar)\n",
    "\n",
    "exhn_relu_mnist, exhn_relu_mnist_fwd = create_model(\"hn_relu_mnist\")\n",
    "_, exhn_relu_mnist = exhn_relu_mnist.init_states_and_params(jax.random.PRNGKey(22))\n",
    "exhn_relu_mnist_fwd(exhn_relu_mnist, xmnist)\n",
    "\n",
    "exhn_relu_cifar, exhn_relu_cifar_fwd = create_model(\"hn_relu_cifar\")\n",
    "_, exhn_relu_cifar = exhn_relu_cifar.init_states_and_params(jax.random.PRNGKey(22))\n",
    "exhn_relu_cifar_fwd(exhn_relu_cifar, xcifar)\n",
    "    \n",
    "# Repu5 model tests\n",
    "exhn_repu5, exhn_repu5_fwd = create_model(\"hn_repu5\", (32,32,3), (10,))\n",
    "_, exhn_repu5 = exhn_repu5.init_states_and_params(jax.random.PRNGKey(22))\n",
    "exhn_repu5_fwd(exhn_repu5, xcifar)\n",
    "\n",
    "exhn_repu5_mnist, exhn_repu5_mnist_fwd = create_model(\"hn_repu5_mnist\")\n",
    "_, exhn_repu5_mnist = exhn_repu5_mnist.init_states_and_params(jax.random.PRNGKey(22))\n",
    "exhn_repu5_mnist_fwd(exhn_repu5_mnist, xmnist)\n",
    "\n",
    "exhn_repu5_cifar, exhn_repu5_cifar_fwd = create_model(\"hn_repu5_cifar\")\n",
    "_, exhn_repu5_cifar = exhn_repu5_cifar.init_states_and_params(jax.random.PRNGKey(22))\n",
    "exhn_repu5_cifar_fwd(exhn_repu5_cifar, xcifar)\n",
    "\n",
    "# Softmax model tests\n",
    "exhn_repu5, exhn_repu5_fwd = create_model(\"hn_repu5\", (32,32,3), (10,))\n",
    "_, exhn_repu5 = exhn_repu5.init_states_and_params(jax.random.PRNGKey(22))\n",
    "exhn_repu5_fwd(exhn_repu5, xcifar)\n",
    "\n",
    "exhn_repu5_mnist, exhn_repu5_mnist_fwd = create_model(\"hn_repu5_mnist\")\n",
    "_, exhn_repu5_mnist = exhn_repu5_mnist.init_states_and_params(jax.random.PRNGKey(22))\n",
    "exhn_repu5_mnist_fwd(exhn_repu5_mnist, xmnist)\n",
    "\n",
    "exhn_repu5_cifar, exhn_repu5_cifar_fwd = create_model(\"hn_repu5_cifar\")\n",
    "_, exhn_repu5_cifar = exhn_repu5_cifar.init_states_and_params(jax.random.PRNGKey(22))\n",
    "exhn_repu5_cifar_fwd(exhn_repu5_cifar, xcifar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4725a8a1-8f44-4f52-b370-f40c831a6cc9",
   "metadata": {},
   "source": [
    "## Simple Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d9abc-be1f-42d4-a020-0d2ab4cca73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@register_model\n",
    "def conv_ham(s1, s2, s3, pool_type, nhid=1000):\n",
    "    layers = [\n",
    "        hmx.TanhLayer(s1, tau=1.0),\n",
    "        hmx.TanhLayer(s2, tau=1.0),\n",
    "        hmx.TanhLayer(s3, tau=1.0),\n",
    "        hmx.SoftmaxLayer((10,), tau=1.0),\n",
    "    ]\n",
    "    synapses = [\n",
    "        hmx.ConvSynapseWithPool(\n",
    "            (4, 4),\n",
    "            strides=(2, 2),\n",
    "            padding=(2, 2),\n",
    "            pool_window=(2, 2),\n",
    "            pool_stride=(2, 2),\n",
    "            pool_type=pool_type,\n",
    "        ),\n",
    "        hmx.ConvSynapseWithPool(\n",
    "            (3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=(0, 0),\n",
    "            pool_window=(2, 2),\n",
    "            pool_stride=(2, 2),\n",
    "            pool_type=pool_type,\n",
    "        ),\n",
    "        hmx.DenseMatrixSynapseWithHiddenLayer(nhid),\n",
    "    ]\n",
    "    connections = [\n",
    "        ((0, 1), 0), \n",
    "        ((1, 2), 1), \n",
    "        ((2, 3), 2)\n",
    "    ]\n",
    "\n",
    "    ham = hmx.HAM(layers, synapses, connections)\n",
    "\n",
    "    forward = ft.partial(fwd_conv, depth=7, dt=0.3)\n",
    "    return ham, forward\n",
    "\n",
    "\n",
    "@register_model\n",
    "def conv_ham_avgpool_mnist(nhid=1000):\n",
    "    return conv_ham((28, 28, 1), (7, 7, 64), (2, 2, 128), pool_type=\"avg\", nhid=nhid)\n",
    "\n",
    "\n",
    "@register_model\n",
    "def conv_ham_maxpool_mnist(nhid=1000):\n",
    "    return conv_ham((28, 28, 1), (7, 7, 64), (2, 2, 128), pool_type=\"max\", nhid=nhid)\n",
    "\n",
    "\n",
    "@register_model\n",
    "def conv_ham_avgpool_cifar(nhid=1000):\n",
    "    return conv_ham((32, 32, 3), (8, 8, 90), (3, 3, 180), pool_type=\"avg\", nhid=nhid)\n",
    "\n",
    "\n",
    "@register_model\n",
    "def conv_ham_maxpool_cifar(nhid=1000):\n",
    "    return conv_ham((32, 32, 3), (8, 8, 90), (3, 3, 180), pool_type=\"max\", nhid=nhid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa36e38f-024c-4eef-93f3-51faec7dc388",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, fwd = create_model(\"conv_ham_avgpool_cifar\")\n",
    "_, model = model.init_states_and_params(jax.random.PRNGKey(0))\n",
    "fwd(model, xcifar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036f93ea-f02a-4285-b0cd-c5da42cf89b1",
   "metadata": {},
   "source": [
    "### Energy Version of Attention\n",
    "\n",
    "We now introduce a simple model for energy-based attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf57d4-9c6a-48f6-8a8b-15df11c0a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@register_model\n",
    "def energy_attn(s1, s2, nheads_self, nheads_cross):\n",
    "    layers = [\n",
    "        hmx.TanhLayer(s1, tau=1.0),\n",
    "        hmx.TanhLayer(s2, tau=1.0, use_bias=True),\n",
    "        hmx.SoftmaxLayer((10,), tau=1.0),\n",
    "    ]\n",
    "\n",
    "    synapses = [\n",
    "        hmx.ConvSynapse((4, 4), strides=(4, 4), padding=(0, 0)),\n",
    "        hmx.AttentionSynapse(num_heads=nheads_cross, zspace_dim=64, stdinit=0.002),\n",
    "        hmx.AttentionSynapse(num_heads=nheads_self, zspace_dim=64, stdinit=0.002),\n",
    "    ]\n",
    "\n",
    "    connections = [(\n",
    "        (0, 1), 0), \n",
    "        ((2, 1), 1), \n",
    "        ((1, 1), 2)\n",
    "    ]\n",
    "    ham = hmx.HAM(layers, synapses, connections)\n",
    "    forward = ft.partial(fwd_conv, depth=5, dt=0.4)\n",
    "\n",
    "    return ham, forward\n",
    "\n",
    "\n",
    "@register_model\n",
    "def energy_attn_mnist():\n",
    "    return energy_attn(\n",
    "        (28, 28, 1),\n",
    "        (7, 7, 128),\n",
    "        nheads_self=4,\n",
    "        nheads_cross=2,\n",
    "    )\n",
    "\n",
    "\n",
    "@register_model\n",
    "def energy_attn_cifar():\n",
    "    return energy_attn(\n",
    "        (32, 32, 3),\n",
    "        (8, 8, 224),\n",
    "        nheads_self=4,\n",
    "        nheads_cross=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23841c-17cf-42a7-9a3e-27d0ac1d8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hamux]",
   "language": "python",
   "name": "conda-env-hamux-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
